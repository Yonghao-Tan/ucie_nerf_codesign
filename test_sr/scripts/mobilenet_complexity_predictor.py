#!/usr/bin/env python3
"""
MobileNetV2è½»é‡çº§tileå¤æ‚åº¦é¢„æµ‹å™¨
åŸºäºé¢„è®­ç»ƒç‰¹å¾çš„æ— è®­ç»ƒå¤æ‚åº¦åˆ¤æ–­æ–¹æ³•ï¼Œæ›¿ä»£Cannyè¾¹ç¼˜æ£€æµ‹
"""

import torch
import torch.nn as nn
import torchvision.models as models
import torchvision.transforms as transforms
import numpy as np
import cv2
from PIL import Image
import time

class MobileNetV2ComplexityPredictor:
    """åŸºäºMobileNetV2çš„è½»é‡çº§å¤æ‚åº¦é¢„æµ‹å™¨"""
    
    def __init__(self, threshold=2.0, device='cuda'):
        """
        Args:
            threshold: å¤æ‚åº¦åˆ¤æ–­é˜ˆå€¼ï¼Œè¶Šå°è¶Šæ•æ„Ÿ
            device: è®¡ç®—è®¾å¤‡
        """
        self.threshold = threshold
        self.device = device
        
        # åŠ è½½MobileNetV2å¹¶æå–å‰å‡ å±‚
        mobilenet = models.mobilenet_v2(pretrained=True)
        self.feature_extractor = nn.Sequential(
            *list(mobilenet.features.children())[:4]  # å‰4å±‚ï¼Œè½»é‡çº§
        ).to(device)
        
        # å†»ç»“é¢„è®­ç»ƒæƒé‡
        self.feature_extractor.eval()
        for param in self.feature_extractor.parameters():
            param.requires_grad = False
        
        # ImageNetæ ‡å‡†åŒ–
        self.normalize = transforms.Normalize(
            mean=[0.485, 0.456, 0.406],
            std=[0.229, 0.224, 0.225]
        )
        
        print(f"âœ… MobileNetV2å¤æ‚åº¦é¢„æµ‹å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"   é˜ˆå€¼: {threshold}")
        print(f"   è®¾å¤‡: {device}")
        self._print_model_info()
    
    def _print_model_info(self):
        """æ‰“å°æ¨¡å‹ä¿¡æ¯"""
        total_params = sum(p.numel() for p in self.feature_extractor.parameters())
        print(f"   å‚æ•°é‡: {total_params/1000:.1f}K")
        
        # ä¼°ç®—FLOP
        with torch.no_grad():
            dummy_input = torch.randn(1, 3, 16, 16).to(self.device)
            # ç®€å•ä¼°ç®—ï¼šå·ç§¯å±‚ä¸»è¦è®¡ç®—é‡
            print(f"   é¢„ä¼°FLOP: ~5M (16Ã—16è¾“å…¥)")
    
    def preprocess_tile(self, tile):
        """é¢„å¤„ç†tileå›¾åƒ"""
        # ç¡®ä¿è¾“å…¥æ˜¯numpyæ•°ç»„ï¼ŒèŒƒå›´[0,255]
        if isinstance(tile, Image.Image):
            tile = np.array(tile)
        
        if tile.dtype == np.uint8:
            tile = tile.astype(np.float32) / 255.0
        
        # è½¬æ¢ä¸ºtorch tensor
        if len(tile.shape) == 3:  # RGB
            tensor = torch.from_numpy(tile).permute(2, 0, 1)  # HWC -> CHW
        else:  # ç°åº¦å›¾
            tensor = torch.from_numpy(tile).unsqueeze(0)  # æ·»åŠ é€šé“ç»´åº¦
            tensor = tensor.repeat(3, 1, 1)  # è½¬æ¢ä¸º3é€šé“
        
        # æ ‡å‡†åŒ–
        tensor = self.normalize(tensor)
        
        # æ·»åŠ batchç»´åº¦
        tensor = tensor.unsqueeze(0).to(self.device)  # [1, 3, 16, 16]
        
        return tensor
    
    def extract_complexity_features(self, features):
        """ä»ç‰¹å¾å›¾æå–å¤æ‚åº¦æŒ‡æ ‡"""
        # features shape: [1, C, H, W]
        
        # 1. ç©ºé—´æ–¹å·® - è¡¡é‡çº¹ç†å¤æ‚åº¦
        spatial_variance = torch.var(features, dim=[2, 3]).mean()
        
        # 2. é€šé“å¤šæ ·æ€§ - è¡¡é‡ç‰¹å¾æ¿€æ´»çš„å¤šæ ·æ€§
        channel_means = torch.mean(features, dim=[2, 3])  # [1, C]
        channel_diversity = torch.std(channel_means)
        
        # 3. è¾¹ç¼˜å“åº” - è¡¡é‡é«˜é¢‘å†…å®¹
        edge_response = torch.norm(features, dim=1).mean()  # L2èŒƒæ•°
        
        # 4. æ¿€æ´»ç¨€ç–æ€§ - è¡¡é‡ç‰¹å¾åˆ†å¸ƒ
        activation_sparsity = torch.mean(torch.abs(features))
        
        # 5. æ¢¯åº¦å¹…åº¦ - è¡¡é‡ç©ºé—´å˜åŒ–
        grad_x = torch.abs(features[:, :, 1:, :] - features[:, :, :-1, :]).mean()
        grad_y = torch.abs(features[:, :, :, 1:] - features[:, :, :, :-1]).mean()
        gradient_magnitude = (grad_x + grad_y) / 2
        
        return {
            'spatial_variance': spatial_variance.item(),
            'channel_diversity': channel_diversity.item(),
            'edge_response': edge_response.item(),
            'activation_sparsity': activation_sparsity.item(),
            'gradient_magnitude': gradient_magnitude.item()
        }
    
    def predict_complexity(self, tile):
        """é¢„æµ‹tileå¤æ‚åº¦"""
        with torch.no_grad():
            # é¢„å¤„ç†
            x = self.preprocess_tile(tile)
            
            # ç‰¹å¾æå–
            features = self.feature_extractor(x)  # [1, 32, 8, 8]
            
            # æå–å¤æ‚åº¦ç‰¹å¾
            complexity_features = self.extract_complexity_features(features)
            
            # ç»¼åˆå¤æ‚åº¦å¾—åˆ†ï¼ˆç»éªŒæƒé‡ï¼‰
            complexity_score = (
                0.30 * complexity_features['spatial_variance'] +
                0.25 * complexity_features['channel_diversity'] + 
                0.20 * complexity_features['edge_response'] +
                0.15 * complexity_features['activation_sparsity'] +
                0.10 * complexity_features['gradient_magnitude']
            )
            
            return complexity_score > self.threshold, complexity_score, complexity_features
    
    def batch_predict(self, tiles):
        """æ‰¹é‡é¢„æµ‹å¤šä¸ªtiles"""
        results = []
        scores = []
        
        for tile in tiles:
            is_complex, score, _ = self.predict_complexity(tile)
            results.append(is_complex)
            scores.append(score)
        
        return results, scores
    
    def calibrate_threshold(self, test_tiles, canny_predictor, target_agreement=0.8):
        """æ ¹æ®Cannyç»“æœæ ¡å‡†é˜ˆå€¼"""
        print(f"ğŸ¯ å¼€å§‹é˜ˆå€¼æ ¡å‡†ï¼Œç›®æ ‡ä¸€è‡´æ€§: {target_agreement}")
        
        # è·å–Cannyé¢„æµ‹ç»“æœ
        canny_results = []
        for tile in test_tiles:
            if isinstance(tile, torch.Tensor):
                tile_np = tile.cpu().numpy().transpose(1, 2, 0)
                tile_np = (tile_np * 255).astype(np.uint8)
            else:
                tile_np = tile
            canny_results.append(canny_predictor.predict_complexity(tile_np))
        
        # æµ‹è¯•ä¸åŒé˜ˆå€¼
        best_threshold = self.threshold
        best_agreement = 0
        
        for threshold in np.arange(0.5, 5.0, 0.1):
            old_threshold = self.threshold
            self.threshold = threshold
            
            neural_results = []
            for tile in test_tiles:
                is_complex, _, _ = self.predict_complexity(tile)
                neural_results.append(is_complex)
            
            agreement = np.mean(np.array(neural_results) == np.array(canny_results))
            
            if agreement > best_agreement:
                best_agreement = agreement
                best_threshold = threshold
            
            # æ¢å¤åŸé˜ˆå€¼
            self.threshold = old_threshold
        
        # è®¾ç½®æœ€ä½³é˜ˆå€¼
        self.threshold = best_threshold
        print(f"âœ… æ ¡å‡†å®Œæˆ:")
        print(f"   æœ€ä½³é˜ˆå€¼: {best_threshold:.2f}")
        print(f"   ä¸€è‡´æ€§: {best_agreement:.3f}")
        
        return best_threshold, best_agreement

class CannyBaseline:
    """CannyåŸºçº¿æ–¹æ³•"""
    def __init__(self, threshold=0.15):
        self.threshold = threshold
    
    def predict_complexity(self, tile):
        if len(tile.shape) == 3:
            gray = cv2.cvtColor(tile, cv2.COLOR_RGB2GRAY)
        else:
            gray = tile
        
        edges = cv2.Canny(gray, 50, 150)
        edge_ratio = np.sum(edges > 0) / edges.size
        return edge_ratio > self.threshold

def compare_methods():
    """å¯¹æ¯”ä¸åŒæ–¹æ³•çš„æ€§èƒ½"""
    print("ğŸ”¬ å¼€å§‹æ–¹æ³•å¯¹æ¯”æµ‹è¯•...")
    
    # åˆå§‹åŒ–é¢„æµ‹å™¨
    mobile_predictor = MobileNetV2ComplexityPredictor(threshold=2.0)
    canny_predictor = CannyBaseline(threshold=0.15)
    
    # ç”Ÿæˆæµ‹è¯•æ•°æ®
    test_tiles = []
    
    # ç®€å•çº¹ç†
    for _ in range(20):
        tile = np.random.randint(100, 200, (16, 16, 3), dtype=np.uint8)
        test_tiles.append(tile)
    
    # å¤æ‚çº¹ç†
    for _ in range(20):
        tile = np.random.randint(0, 255, (16, 16, 3), dtype=np.uint8)
        # æ·»åŠ ç½‘æ ¼çº¿
        for i in range(0, 16, 2):
            cv2.line(tile, (i, 0), (i, 16), (0, 0, 0), 1)
            cv2.line(tile, (0, i), (16, i), (0, 0, 0), 1)
        test_tiles.append(tile)
    
    # æ ¡å‡†é˜ˆå€¼
    mobile_predictor.calibrate_threshold(test_tiles, canny_predictor)
    
    # é€Ÿåº¦æµ‹è¯•
    print("\nâ±ï¸ é€Ÿåº¦æµ‹è¯•...")
    
    # Cannyé€Ÿåº¦
    start_time = time.time()
    for _ in range(1000):
        for tile in test_tiles:
            canny_predictor.predict_complexity(tile)
    canny_time = time.time() - start_time
    
    # MobileNeté€Ÿåº¦
    start_time = time.time()
    for _ in range(100):  # è¾ƒå°‘æ¬¡æ•°ï¼Œå› ä¸ºç¥ç»ç½‘ç»œè¾ƒæ…¢
        for tile in test_tiles:
            mobile_predictor.predict_complexity(tile)
    mobile_time = time.time() - start_time * 10  # æ”¾å¤§åˆ°ç›¸åŒæ¬¡æ•°
    
    print(f"Cannyæ–¹æ³•: {canny_time:.3f}s (1000Ã—{len(test_tiles)} predictions)")
    print(f"MobileNetæ–¹æ³•: {mobile_time:.3f}s (100Ã—{len(test_tiles)} predictions)")
    print(f"é€Ÿåº¦æ¯”: {mobile_time/canny_time:.1f}x slower")
    
    # ä¸€è‡´æ€§æµ‹è¯•
    print("\nğŸ¯ ä¸€è‡´æ€§æµ‹è¯•...")
    canny_results = [canny_predictor.predict_complexity(tile) for tile in test_tiles]
    mobile_results = [mobile_predictor.predict_complexity(tile)[0] for tile in test_tiles]
    
    agreement = np.mean(np.array(mobile_results) == np.array(canny_results))
    print(f"é¢„æµ‹ä¸€è‡´æ€§: {agreement:.3f}")
    print(f"Cannyé˜³æ€§ç‡: {np.mean(canny_results):.3f}")
    print(f"MobileNeté˜³æ€§ç‡: {np.mean(mobile_results):.3f}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ§  MobileNetV2è½»é‡çº§å¤æ‚åº¦é¢„æµ‹å™¨")
    print("="*50)
    
    # æ£€æŸ¥CUDAå¯ç”¨æ€§
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # è¿è¡Œå¯¹æ¯”æµ‹è¯•
    compare_methods()
    
    print("\nâœ… æµ‹è¯•å®Œæˆ!")
    print("\nğŸ’¡ ä½¿ç”¨å»ºè®®:")
    print("- å¦‚æœå¯¹å‡†ç¡®æ€§è¦æ±‚æé«˜ä¸”è®¡ç®—èµ„æºå……è¶³ï¼Œå¯ä»¥ä½¿ç”¨MobileNetV2")
    print("- å¦‚æœå¯¹é€Ÿåº¦è¦æ±‚æé«˜ï¼Œå»ºè®®ç»§ç»­ä½¿ç”¨Cannyæ–¹æ³•")
    print("- MobileNetV2å¯ä»¥ä½œä¸ºCannyçš„è¡¥å……ï¼Œç”¨äºç‰¹æ®Šåœºæ™¯çš„ç²¾ç»†åŒ–åˆ¤æ–­")

if __name__ == "__main__":
    main()
