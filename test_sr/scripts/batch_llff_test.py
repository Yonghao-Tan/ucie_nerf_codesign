#!/usr/bin/env python3
import os
import sys
import numpy as np
import cv2
from PIL import Image
import matplotlib.pyplot as plt
from skimage.metrics import peak_signal_noise_ratio as psnr
import pandas as pd
from pathlib import Path
import time
from tqdm import tqdm
import torch
import torch.nn as nn
import torchvision.models as models
import torchvision.transforms as transforms

# æ·»åŠ å½“å‰è„šæœ¬ç›®å½•åˆ°è·¯å¾„ï¼Œä»¥ä¾¿å¯¼å…¥æˆ‘ä»¬çš„é¢„æµ‹å™¨
sys.path.append('/home/ytanaz/access/IBRNet/test_sr/scripts')

# è®¾ç½®matplotlibæ”¯æŒä¸­æ–‡
# plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'SimHei', 'Arial Unicode MS']
# plt.rcParams['axes.unicode_minus'] = False
# è®¾ç½®matplotlibä½¿ç”¨è‹±æ–‡ï¼Œé¿å…ä¸­æ–‡å­—ä½“é—®é¢˜
plt.rcParams['font.family'] = 'DejaVu Sans'
plt.rcParams['axes.unicode_minus'] = False

class BatchTileReplacementTester:
    """æ‰¹é‡tileæ›¿æ¢æµ‹è¯•å™¨"""

    def __init__(self, llff_test_root="/home/ytanaz/access/IBRNet/eval/llff_test"):
        self.llff_test_root = Path(llff_test_root)
        self.eval_llff_path = self.llff_test_root / "eval_llff_golden" # TODO
        self.eval_llff_sr_path = self.llff_test_root / "eval_llff_sr"
        self.tile_size = 32
        self.tile_size = 20
        self.fine_tile_size = self.tile_size // 2  # åœ¨fineåˆ†è¾¨ç‡ä¸Šçš„tileå¤§å°
        
        # é¢„è®¾é˜ˆå€¼
        self.canny_threshold = 0.160  # é«˜åˆ†è¾¨ç‡æ–¹æ³•çš„é˜ˆå€¼
        self.canny_threshold_lowres = 0.250  # ä½åˆ†è¾¨ç‡æ ¡æ­£åçš„é˜ˆå€¼
        
        print(f"ğŸ” æ‰¹é‡æµ‹è¯•å™¨åˆå§‹åŒ–")
        print(f"LLFFæµ‹è¯•æ ¹ç›®å½•: {self.llff_test_root}")
        print(f"Cannyé«˜åˆ†è¾¨ç‡é˜ˆå€¼: {self.canny_threshold}")
        print(f"Cannyä½åˆ†è¾¨ç‡é˜ˆå€¼: {self.canny_threshold_lowres}")

    def get_scenes(self, special_scene=None):
        """è·å–æ‰€æœ‰æµ‹è¯•åœºæ™¯"""
        scenes = []
        print(special_scene)
        if self.eval_llff_path.exists():
            for scene_dir in self.eval_llff_path.iterdir():
                if special_scene is None:
                    if scene_dir.is_dir() and not scene_dir.name.startswith('.'):
                        scenes.append(scene_dir.name)
                elif scene_dir.is_dir() and not scene_dir.name.startswith('.') and special_scene in scene_dir.name:
                    scenes.append(scene_dir.name)
        return sorted(scenes)
    
    def get_image_indices(self, scene_path):
        """è·å–åœºæ™¯ä¸­æ‰€æœ‰å›¾åƒçš„ç´¢å¼•"""
        indices = []
        for file_path in scene_path.glob("*_gt_rgb.png"):
            index = int(file_path.stem.split('_')[0])
            indices.append(index)
        return sorted(indices)
    

    def extract_edge_score_canny(self, tile):
        """æå–Cannyè¾¹ç¼˜å¾—åˆ†"""
        if tile.max() > 1.0:
            tile = tile.astype(np.float32) / 255.0
            
        # è½¬æ¢ä¸ºç°åº¦å›¾
        if len(tile.shape) == 3:
            gray = cv2.cvtColor((tile * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)
        else:
            gray = (tile * 255).astype(np.uint8)
            
        # Cannyè¾¹ç¼˜æ£€æµ‹
        edges = cv2.Canny(gray, 50, 150)
        # edges = manual_canny(gray, 50, 150)
        edge_ratio = np.sum(edges > 0) / edges.size
        # print('a',edge_ratio)
        # edges = self_canny(gray, 5, 15)
        # edge_ratio = float(edges) / gray.size
        # print('b',edge_ratio)
        return edge_ratio
    
    def density_complexity_metric(self, tile_sigma, 
                             sigma_threshold=0.5,
                             grad_threshold=0.3,
                             curvature_threshold=0.2):
        """
        çº¯å¯†åº¦åœºå¤æ‚åº¦æŒ‡æ ‡ï¼ˆDensity Complexity Metric, DCMï¼‰
        
        å‚æ•°:
            tile_sigma: [tile_size, tile_size, num_samples] 
                    å¯†åº¦åœºé‡‡æ ·å€¼ (sigma)ï¼Œæ²¿å…‰çº¿çš„é‡‡æ ·ç‚¹
            sigma_threshold: å¯†åº¦é˜ˆå€¼ (é»˜è®¤0.5)ï¼Œç”¨äºç­›é€‰è¡¨é¢åŒºåŸŸ
            grad_threshold: æ¢¯åº¦é˜ˆå€¼ (é»˜è®¤0.3)ï¼Œç”¨äºç­›é€‰é«˜å˜åŒ–åŒºåŸŸ
            curvature_threshold: æ›²ç‡é˜ˆå€¼ (é»˜è®¤0.2)
        
        è¿”å›:
            dcm_score: å¯†åº¦å¤æ‚åº¦å¾—åˆ† (0~1)
            need_full_render: æ˜¯å¦éœ€è¦å®Œæ•´NeRFæ¸²æŸ“ (True/False)
        """
        # 1. æå–è¡¨é¢åŒºåŸŸï¼ˆé«˜å¯†åº¦åŒºåŸŸï¼‰
        surface_mask = (tile_sigma > sigma_threshold)  # [H, W, N]
        
        # 2. è®¡ç®—å¯†åº¦æ¢¯åº¦ï¼ˆæ²¿å…‰çº¿æ–¹å‘ï¼‰
        d_sigma = np.diff(tile_sigma, axis=-1)  # [H, W, N-1]
        grad_mag = np.abs(d_sigma)  # æ¢¯åº¦å¹…å€¼
        
        # 3. è®¡ç®—è¡¨é¢æ¢¯åº¦å¼ºåº¦ï¼ˆä»…è€ƒè™‘è¡¨é¢åŒºåŸŸï¼‰
        surface_grad = grad_mag * surface_mask[..., :-1]  # [H, W, N-1]
        avg_surface_grad = np.mean(surface_grad)
        
        # 4. è®¡ç®—è¡¨é¢æ›²ç‡ï¼ˆäºŒé˜¶å¯¼æ•°ï¼‰
        d2_sigma = np.diff(d_sigma, axis=-1)  # [H, W, N-2]
        curvature = np.abs(d2_sigma) * surface_mask[..., 2:]  # ä»…è¡¨é¢åŒºåŸŸ
        avg_curvature = np.mean(curvature)
        
        # 5. è®¡ç®—å¤šå±‚è¡¨é¢æŒ‡æ ‡ï¼ˆé˜²æ­¢è–„ç‰©ä½“æ¼æ£€ï¼‰
        layer_count = np.sum(surface_mask, axis=-1)  # æ¯åƒç´ çš„è¡¨é¢å±‚æ•°
        multi_layer_ratio = np.mean(layer_count >= 2)  # å¤šå±‚è¡¨é¢å æ¯”
        
        # 6. èåˆæŒ‡æ ‡ â†’ DCMå¾—åˆ†
        dcm_score = (
            0.5 * np.clip(avg_surface_grad / grad_threshold, 0, 1) +
            0.3 * np.clip(avg_curvature / curvature_threshold, 0, 1) +
            0.2 * multi_layer_ratio
        )
        
        # 7. å†³ç­–ï¼ˆé˜ˆå€¼å¯è°ƒï¼‰
        need_full_render = (dcm_score > 0.6)
        
        return dcm_score, need_full_render

    def extract_volume_rendering_confidence(self, tile_weights, tile):
        """
        åŸºäºä½“æ¸²æŸ“æƒé‡çš„ç½®ä¿¡åº¦è¯„ä¼°
        
        Args:
            tile_weights: [tile_h, tile_w, n_samples] çš„æƒé‡å¼ é‡
            
        Returns:
            confidence_score: ç½®ä¿¡åº¦å¾—åˆ†ï¼Œè¶Šé«˜è¡¨ç¤ºæ¸²æŸ“è¶Šä¸ç¡®å®šï¼Œè¶Šéœ€è¦é«˜è´¨é‡æ¸²æŸ“
        """
        if tile_weights is None:
            return 0.0
        
        # ç¡®ä¿æ˜¯numpyæ•°ç»„
        if hasattr(tile_weights, 'cpu'):
            weights = tile_weights.cpu().numpy()
        else:
            weights = tile_weights
        # print(weights.shape, tile.shape)
        dcm_score, need_full_render = self.density_complexity_metric(weights, 
                    sigma_threshold=0.5,
                    grad_threshold=0.3,
                    curvature_threshold=0.2)
        
        if tile.max() > 1.0:
            tile = tile.astype(np.float32) / 255.0
            
        # è½¬æ¢ä¸ºç°åº¦å›¾
        if len(tile.shape) == 3:
            gray = cv2.cvtColor((tile * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)
        else:
            gray = (tile * 255).astype(np.uint8)
            
        # Cannyè¾¹ç¼˜æ£€æµ‹
        edges = cv2.Canny(gray, 50, 150)
        edge_ratio = np.sum(edges > 0) / edges.size
        # print(dcm_score, edge_ratio)
        threshold = 0.37
        return dcm_score * 0.4 + edge_ratio, threshold
        # # 1. æƒé‡åˆ†å¸ƒç†µ - è¡¡é‡é‡‡æ ·ç‚¹æƒé‡çš„ä¸ç¡®å®šæ€§
        # weights_norm = weights / (weights.sum(axis=-1, keepdims=True) + 1e-8)
        # # é¿å…log(0)
        # weights_safe = weights_norm + 1e-8
        # weights_entropy = -np.sum(weights_norm * np.log(weights_safe), axis=-1)
        # mean_entropy = np.mean(weights_entropy)
        
        # # 2. æƒé‡é›†ä¸­åº¦ - æœ€å¤§æƒé‡å€¼çš„å¹³å‡
        # max_weights = np.max(weights, axis=-1)
        # weight_concentration = np.mean(max_weights)
        
        # # 3. æœ‰æ•ˆé‡‡æ ·ç‚¹æ¯”ä¾‹ - æƒé‡æ˜¾è‘—çš„é‡‡æ ·ç‚¹æ•°é‡
        # threshold = 0.05 * np.max(weights, axis=-1, keepdims=True)
        # effective_samples = np.sum(weights > threshold, axis=-1)
        # effective_ratio = np.mean(effective_samples) / weights.shape[-1]
        
        # # ç»¼åˆç½®ä¿¡åº¦å¾—åˆ†ï¼ˆå½’ä¸€åŒ–åˆ°0-1èŒƒå›´ï¼‰
        # # é«˜ç†µã€ä½é›†ä¸­åº¦ã€åˆ†æ•£çš„æœ‰æ•ˆé‡‡æ ·ç‚¹ = é«˜ä¸ç¡®å®šæ€§ = éœ€è¦ç²¾ç»†æ¸²æŸ“
        # max_entropy = np.log(weights.shape[-1])  # æœ€å¤§å¯èƒ½ç†µ
        # normalized_entropy = mean_entropy / max_entropy
        
        # confidence_score = (
        #     0.5 * normalized_entropy +              # æƒé‡åˆ†å¸ƒä¸ç¡®å®šæ€§
        #     0.3 * (1.0 - weight_concentration) +    # æƒé‡åˆ†æ•£åº¦  
        #     0.2 * effective_ratio                   # æœ‰æ•ˆé‡‡æ ·ç‚¹åˆ†æ•£åº¦
        # )
        
        # return float(np.clip(confidence_score, 0, 1))
    
    # def extract_depth_discontinuity_score(self, tile_depth, percentile=90):
    def extract_depth_discontinuity_score(self, tile_depth, 
                                          tile,
                           depth_var_threshold=0.15,
                           grad_threshold=0.05,
                           curvature_threshold=0.1):
        """
        çº¯æ·±åº¦å›¾å¤æ‚åº¦æŒ‡æ ‡ï¼ˆDepth Complexity Metric, DCMï¼‰
        
        å‚æ•°:
            tile_depth: [tile_size, tile_size] æ·±åº¦å›¾ (0~1)
            depth_var_threshold: æ·±åº¦æ–¹å·®é˜ˆå€¼ (ç”¨äºä½çº¹ç†åŒºåŸŸæ£€æµ‹)
            grad_threshold: æ·±åº¦æ¢¯åº¦é˜ˆå€¼ (ç”¨äºè¾¹ç•Œæ£€æµ‹)
            curvature_threshold: æ›²ç‡é˜ˆå€¼ (ç”¨äºå°–é”è¾¹ç¼˜æ£€æµ‹)
        
        è¿”å›:
            dcm_score: æ·±åº¦å¤æ‚åº¦å¾—åˆ† (0~1)
            need_full_render: æ˜¯å¦éœ€è¦å®Œæ•´NeRFæ¸²æŸ“
        """
        # === Step 1: æ·±åº¦å›¾é¢„å¤„ç† ===
        # å½’ä¸€åŒ–åˆ°[0,1]ï¼ˆå¦‚æœå°šæœªå½’ä¸€åŒ–ï¼‰
        tile_depth = tile_depth.numpy()
        if tile_depth.max() > 1.0:
            tile_depth = (tile_depth - tile_depth.min()) / (tile_depth.max() - tile_depth.min() + 1e-5)
        
        # === Step 2: è®¡ç®—å‡ ä½•å…³é”®æŒ‡æ ‡ ===
        # 2.1 æ·±åº¦æ–¹å·®ï¼ˆæ•´ä½“å¤æ‚åº¦ï¼‰
        depth_var = np.var(tile_depth)
        
        # 2.2 æ·±åº¦æ¢¯åº¦ï¼ˆè¾¹ç•Œå¼ºåº¦ï¼‰
        grad_x = cv2.Sobel(tile_depth, cv2.CV_32F, 1, 0, ksize=3)
        grad_y = cv2.Sobel(tile_depth, cv2.CV_32F, 0, 1, ksize=3)
        grad_mag = np.sqrt(grad_x**2 + grad_y**2 + 1e-5)
        edge_ratio = np.mean(grad_mag > grad_threshold)  # æ·±åº¦è¾¹ç•Œå æ¯”
        
        # 2.3 è¡¨é¢æ›²ç‡ï¼ˆå¼¯æ›²åº¦ï¼‰
        laplacian = cv2.Laplacian(tile_depth, cv2.CV_32F)
        curvature_ratio = np.mean(np.abs(laplacian) > curvature_threshold)
        
        # === Step 3: èåˆæŒ‡æ ‡ â†’ DCMå¾—åˆ† ===
        # æƒé‡è®¾è®¡ï¼šæ¢¯åº¦æœ€é‡è¦ï¼ˆç›´æ¥å¯¹åº”è¾¹ç•Œï¼‰ï¼Œæ›²ç‡æ¬¡ä¹‹
        dcm_score = (
            0.5 * np.clip(depth_var / depth_var_threshold, 0, 1) +
            0.3 * edge_ratio +
            0.2 * curvature_ratio
        )
        
        # === Step 4: è‡ªé€‚åº”å†³ç­– ===
        # ä½çº¹ç†åŒºåŸŸç‰¹æ®Šå¤„ç†ï¼ˆæ·±åº¦å›¾å¯èƒ½ä¸å¯é ï¼‰
        if depth_var < 0.01:
            # ç”¨æ›²ç‡ä½œä¸ºä¸»è¦æŒ‡æ ‡ï¼ˆä½çº¹ç†åŒºåŸŸæ›²ç‡ä»å¯é ï¼‰
            dcm_score = 0.7 * curvature_ratio + 0.3 * edge_ratio
        
        if tile.max() > 1.0:
            tile = tile.astype(np.float32) / 255.0
            
        # è½¬æ¢ä¸ºç°åº¦å›¾
        if len(tile.shape) == 3:
            gray = cv2.cvtColor((tile * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)
        else:
            gray = (tile * 255).astype(np.uint8)
        # Cannyè¾¹ç¼˜æ£€æµ‹
        edges = cv2.Canny(gray, 50, 150)
        edge_ratio = np.sum(edges > 0) / edges.size
            
        threshold = 0.42
        dcm_score = dcm_score * 0.3 + edge_ratio
        
        return dcm_score, threshold
    
    def compute_gacm(self, tile_color, tile_depth, 
                     alpha=0.4, beta=0.3, gamma=0.3, 
                     tau_D_ratio=0.1, threshold=0.25):
        """
        è®¡ç®—å‡ ä½•æ„ŸçŸ¥å¤æ‚åº¦æŒ‡æ ‡ (GACM) - ç¬¬ä¸‰ç§åˆ›æ–°NeRFæ„ŸçŸ¥æ–¹æ³•
        
        å‚æ•°:
            tile_color: [32, 32, 3] é™é‡‡æ ·é¢œè‰²å›¾åƒ (torch.Tensor, 0~1)
            tile_depth: [32, 32] é™é‡‡æ ·æ·±åº¦å›¾ (torch.Tensor)
            alpha, beta, gamma: DD, SC, GAE çš„æƒé‡ (é»˜è®¤ 0.4, 0.3, 0.3)
            tau_D_ratio: æ·±åº¦æ¢¯åº¦é˜ˆå€¼æ¯”ä¾‹ (é»˜è®¤ 0.1 â†’ tau_D = 0.1 * max(G_D))
            threshold: æœ€ç»ˆå†³ç­–é˜ˆå€¼ (é»˜è®¤ 0.25)
        
        è¿”å›:
            gacm_score: å‡ ä½•å¤æ‚åº¦å¾—åˆ† (0~1)
            decision: bool (True=éœ€å®Œæ•´NeRF, False=å¯è¶…åˆ†)
        """
        # === Step 0: æ·±åº¦å›¾é¢„å¤„ç† (å…³é”®ï¼é¿å…å™ªå£°å¹²æ‰°) ===
        depth = tile_depth.clone()
        # å½’ä¸€åŒ–æ·±åº¦åˆ° [0,1] (é€‚é…ä¸åŒåœºæ™¯å°ºåº¦)
        depth_min, depth_max = depth.min(), depth.max()
        depth = (depth - depth_min) / (depth_max - depth_min + 1e-5)
        
        # === Step 1: è®¡ç®—æ·±åº¦é©±åŠ¨çš„å‡ ä½•å¤æ‚åº¦ ===
        # 1.1 æ·±åº¦ä¸è¿ç»­æ€§ (Depth Discontinuity, DD)
        sobel_x = torch.tensor([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], dtype=torch.float32, device=depth.device)
        sobel_y = sobel_x.T
        grad_x = torch.nn.functional.conv2d(depth[None, None], sobel_x[None, None], padding=1)[0,0]
        grad_y = torch.nn.functional.conv2d(depth[None, None], sobel_y[None, None], padding=1)[0,0]
        G_D = torch.sqrt(grad_x**2 + grad_y**2 + 1e-5)  # é¿å…é™¤é›¶
        DD_tile = G_D.mean().item()
        
        # 1.2 è¡¨é¢æ›²ç‡ (Surface Curvature, SC)
        laplacian = torch.nn.functional.conv2d(
            depth[None, None], 
            torch.tensor([[0, 1, 0], [1, -4, 1], [0, 1, 0]], dtype=torch.float32, device=depth.device)[None, None],
            padding=1
        )[0,0]
        SC_tile = torch.abs(laplacian).mean().item()
        
        # === Step 2: è®¡ç®—å‡ ä½•å¯¹é½è¾¹ç¼˜ (Geometry-Aligned Edges, GAE) ===
        # 2.1 ç”¨Cannyæ£€æµ‹é¢œè‰²è¾¹ç¼˜ (CPUæ“ä½œï¼Œå› OpenCVä¸æ”¯æŒGPU)
        color_np = (tile_color.cpu().numpy() * 255).astype('uint8')
        gray = cv2.cvtColor(color_np, cv2.COLOR_RGB2GRAY)
        edges_canny = cv2.Canny(gray, 100, 200)  # æ ‡å‡†Cannyå‚æ•°
        
        # 2.2 ä»…ä¿ç•™ä¸æ·±åº¦ä¸è¿ç»­å¯¹é½çš„è¾¹ç¼˜ (æ ¸å¿ƒåˆ›æ–°!)
        tau_D = tau_D_ratio * G_D.max().item()  # æ·±åº¦æ¢¯åº¦é˜ˆå€¼
        G_D_np = G_D.cpu().numpy()
        GAE = edges_canny * (G_D_np > tau_D)  # å…³é”®ï¼šè¿‡æ»¤éå‡ ä½•è¾¹ç¼˜
        GAE_density = GAE.sum() / (32*32*255)  # å½’ä¸€åŒ–åˆ° [0,1]
        
        # === Step 3: èåˆæŒ‡æ ‡ â†’ GACM ===
        gacm_score = alpha * DD_tile + beta * SC_tile + gamma * GAE_density
        
        # === Step 4: å†³ç­– ===
        decision = (gacm_score > threshold)
        
        return gacm_score, decision
    
    def depth_discontinuity_method(self, sr_img, fine_img, org_img, render_depth_path, threshold=0.7):
        """
        åŸºäºæ·±åº¦ä¸è¿ç»­æ€§çš„tileæ›¿æ¢æ–¹æ³•
        
        å·¥ä½œæµç¨‹:
        1. fineå›¾åƒ (378x504) çš„æ·±åº¦å›¾ â†’ åˆ†æå‡ ä½•å¤æ‚åº¦
        2. SRå›¾åƒ (756x1008) çš„32x32 tile â† fineå›¾åƒ16x16åŒºåŸŸ (2å€å¯¹åº”)
        3. å¦‚æœfineåŒºåŸŸå‡ ä½•å¤æ‚ï¼Œç”¨org_imgçš„å¯¹åº”tileæ›¿æ¢
        
        Args:
            sr_img: è¶…åˆ†è¾¨ç‡å›¾åƒ [756, 1008, 3]
            org_img: åŸå§‹é«˜è´¨é‡å›¾åƒ [756, 1008, 3]
            render_depth_path: æ¸²æŸ“æ·±åº¦å›¾æ–‡ä»¶è·¯å¾„ (fineåˆ†è¾¨ç‡)
            threshold: ä¸è¿ç»­æ€§é˜ˆå€¼
        """
        import torch
        
        # åŠ è½½æ·±åº¦å›¾ (fineåˆ†è¾¨ç‡: 378x504)
        try:
            fine_depth = torch.load(render_depth_path, map_location='cpu')
        except Exception as e:
            print(f"âŒ åŠ è½½æ·±åº¦å›¾å¤±è´¥: {e}")
            return sr_img, 0
        
        # SRå›¾åƒå°ºå¯¸
        sr_h, sr_w = sr_img.shape[:2]
        sr_tile_h, sr_tile_w = sr_h // self.tile_size, sr_w // self.tile_size
        
        # Fineå›¾åƒå°ºå¯¸ (åº”è¯¥æ˜¯SRçš„ä¸€åŠ)
        fine_h, fine_w = fine_depth.shape[:2]
        fine_tile_size = self.fine_tile_size  # 16x16
        fine_tile_h, fine_tile_w = fine_h // fine_tile_size, fine_w // fine_tile_size
        
        # ç¡®ä¿tileæ•°é‡åŒ¹é…
        assert sr_tile_h == fine_tile_h and sr_tile_w == fine_tile_w, \
            f"Tileæ•°é‡ä¸åŒ¹é…: SR {sr_tile_h}x{sr_tile_w} vs Fine {fine_tile_h}x{fine_tile_w}"
        
        hybrid_img = sr_img.copy()
        replaced_tiles = 0
        tile_scores = []
        
        # é€tileåˆ†æ (åŒæ—¶å¤„ç†fineå’ŒSRå¯¹åº”çš„tiles)
        for i in range(fine_tile_h):
            for j in range(fine_tile_w):
                # Fineæ·±åº¦å›¾ä¸­çš„tileåæ ‡ (16x16)
                fine_h_start = i * fine_tile_size
                fine_h_end = (i + 1) * fine_tile_size
                fine_w_start = j * fine_tile_size  
                fine_w_end = (j + 1) * fine_tile_size
                
                # SRå›¾åƒä¸­å¯¹åº”çš„tileåæ ‡ (32x32)
                sr_h_start = i * self.tile_size
                sr_h_end = (i + 1) * self.tile_size
                sr_w_start = j * self.tile_size
                sr_w_end = (j + 1) * self.tile_size
                
                # ä»fineæ·±åº¦å›¾ä¸­æå–å¯¹åº”çš„tile
                fine_depth_tile = fine_depth[fine_h_start:fine_h_end, fine_w_start:fine_w_end]
                
                fine_tile = fine_img[fine_h_start:fine_h_end, fine_w_start:fine_w_end]
                
                # è®¡ç®—æ·±åº¦ä¸è¿ç»­æ€§å¾—åˆ† (åŸºäºfineæ·±åº¦)
                discontinuity_score, threshold = self.extract_depth_discontinuity_score(fine_depth_tile, fine_tile)
                tile_scores.append(discontinuity_score)
                
                # æ›¿æ¢å†³ç­–: å¦‚æœä¸è¿ç»­æ€§é«˜(å‡ ä½•å¤æ‚)ï¼Œåˆ™æ›¿æ¢SR tile
                if discontinuity_score > threshold:
                    hybrid_img[sr_h_start:sr_h_end, sr_w_start:sr_w_end] = \
                        org_img[sr_h_start:sr_h_end, sr_w_start:sr_w_end]
                    replaced_tiles += 1
        
        replacement_ratio = replaced_tiles / (fine_tile_h * fine_tile_w)
        
        return hybrid_img, replaced_tiles
    
    def gacm_method(self, sr_img, org_img, render_depth_path, threshold=0.65, 
                    alpha=0.4, beta=0.3, gamma=0.3, tau_D_ratio=0.1):
        """
        GACM (å‡ ä½•æ„ŸçŸ¥å¤æ‚åº¦æŒ‡æ ‡) æ–¹æ³•ï¼šèåˆæ·±åº¦+æ›²ç‡+å‡ ä½•å¯¹é½è¾¹ç¼˜
        
        å·¥ä½œæµç¨‹:
        1. fineå›¾åƒ (378x504) çš„æ·±åº¦å›¾ â†’ è®¡ç®—DDå’ŒSC
        2. SRå›¾åƒ (756x1008) çš„32x32 tile â†’ è®¡ç®—GAE
        3. èåˆä¸‰ä¸ªæŒ‡æ ‡å¾—åˆ°GACMå¾—åˆ†ï¼Œè¶…è¿‡é˜ˆå€¼åˆ™ç”¨org_imgæ›¿æ¢
        
        Args:
            sr_img: è¶…åˆ†è¾¨ç‡å›¾åƒ [756, 1008, 3]
            org_img: åŸå§‹é«˜è´¨é‡å›¾åƒ [756, 1008, 3]
            render_depth_path: æ¸²æŸ“æ·±åº¦å›¾æ–‡ä»¶è·¯å¾„ (fineåˆ†è¾¨ç‡)
            threshold: GACMå†³ç­–é˜ˆå€¼
            alpha, beta, gamma: DD, SC, GAEçš„æƒé‡
            tau_D_ratio: æ·±åº¦æ¢¯åº¦é˜ˆå€¼æ¯”ä¾‹
        """
        import torch
        import cv2
        
        # åŠ è½½æ·±åº¦å›¾ (fineåˆ†è¾¨ç‡: 378x504)
        try:
            fine_depth = torch.load(render_depth_path, map_location='cpu')
        except Exception as e:
            print(f"âŒ åŠ è½½æ·±åº¦å›¾å¤±è´¥: {e}")
            return sr_img, 0
        
        # SRå›¾åƒå°ºå¯¸
        sr_h, sr_w = sr_img.shape[:2]
        sr_tile_h, sr_tile_w = sr_h // self.tile_size, sr_w // self.tile_size
        
        # Fineå›¾åƒå°ºå¯¸ (åº”è¯¥æ˜¯SRçš„ä¸€åŠ)
        fine_h, fine_w = fine_depth.shape[:2]
        fine_tile_size = self.fine_tile_size  # 16x16
        fine_tile_h, fine_tile_w = fine_h // fine_tile_size, fine_w // fine_tile_size
        
        # ç¡®ä¿tileæ•°é‡åŒ¹é…
        assert sr_tile_h == fine_tile_h and sr_tile_w == fine_tile_w, \
            f"Tileæ•°é‡ä¸åŒ¹é…: SR {sr_tile_h}x{sr_tile_w} vs Fine {fine_tile_h}x{fine_tile_w}"
        
        hybrid_img = sr_img.copy()
        replaced_tiles = 0
        gacm_scores = []
        
        # é€tileåˆ†æ (åŒæ—¶å¤„ç†fineå’ŒSRå¯¹åº”çš„tiles)
        for i in range(fine_tile_h):
            for j in range(fine_tile_w):
                # Fineæ·±åº¦å›¾ä¸­çš„tileåæ ‡ (16x16)
                fine_h_start = i * fine_tile_size
                fine_h_end = (i + 1) * fine_tile_size
                fine_w_start = j * fine_tile_size  
                fine_w_end = (j + 1) * fine_tile_size
                
                # SRå›¾åƒä¸­å¯¹åº”çš„tileåæ ‡ (32x32)
                sr_h_start = i * self.tile_size
                sr_h_end = (i + 1) * self.tile_size
                sr_w_start = j * self.tile_size
                sr_w_end = (j + 1) * self.tile_size
                
                # ä»fineæ·±åº¦å›¾ä¸­æå–å¯¹åº”çš„tileå¹¶å‡é‡‡æ ·åˆ°32x32
                fine_depth_tile = fine_depth[fine_h_start:fine_h_end, fine_w_start:fine_w_end]
                tile_depth_32 = fine_depth_tile
                # tile_depth_32 = torch.nn.functional.interpolate(
                #     fine_depth_tile[None, None], 
                #     size=(32, 32), 
                #     mode='bilinear'
                # )[0,0]
                
                # ä»SRå›¾åƒä¸­æå–å¯¹åº”çš„é¢œè‰²tile
                sr_tile = sr_img[fine_h_start:fine_h_end, fine_w_start:fine_w_end]
                tile_color = torch.tensor(sr_tile / 255.0, dtype=torch.float32)
                
                # è®¡ç®—GACMå¾—åˆ†å’Œå†³ç­–
                gacm_score, should_replace = self.compute_gacm(
                    tile_color, tile_depth_32, 
                    alpha=alpha, beta=beta, gamma=gamma,
                    tau_D_ratio=tau_D_ratio, threshold=threshold
                )
                gacm_scores.append(gacm_score)
                
                # æ›¿æ¢å†³ç­–: å¦‚æœGACMå†³ç­–ä¸ºéœ€è¦å®Œæ•´NeRFï¼Œåˆ™æ›¿æ¢SR tile
                if should_replace:
                    hybrid_img[sr_h_start:sr_h_end, sr_w_start:sr_w_end] = \
                        org_img[sr_h_start:sr_h_end, sr_w_start:sr_w_end]
                    replaced_tiles += 1
        
        replacement_ratio = replaced_tiles / (fine_tile_h * fine_tile_w)
        
        return hybrid_img, replaced_tiles
    
    def volume_rendering_confidence_method(self, sr_img, fine_img, org_img, render_weights_path, threshold=0.35):
        """
        åŸºäºä½“æ¸²æŸ“ç½®ä¿¡åº¦çš„tileæ›¿æ¢æ–¹æ³•
        
        å·¥ä½œæµç¨‹:
        1. fineå›¾åƒ (378x504) çš„æƒé‡ â†’ åˆ¤æ–­è´¨é‡
        2. SRå›¾åƒ (756x1008) çš„32x32 tile â† fineå›¾åƒ16x16åŒºåŸŸ (2å€å¯¹åº”)
        3. å¦‚æœfineåŒºåŸŸè´¨é‡ä¸å¤Ÿï¼Œç”¨org_imgçš„å¯¹åº”tileæ›¿æ¢
        
        Args:
            sr_img: è¶…åˆ†è¾¨ç‡å›¾åƒ [756, 1008, 3]
            org_img: åŸå§‹é«˜è´¨é‡å›¾åƒ [756, 1008, 3]
            render_weights_path: æ¸²æŸ“æƒé‡æ–‡ä»¶è·¯å¾„ (fineåˆ†è¾¨ç‡)
            threshold: ç½®ä¿¡åº¦é˜ˆå€¼
        """
        import torch
        
        # åŠ è½½æ¸²æŸ“æƒé‡ (fineåˆ†è¾¨ç‡: 378x504)
        try:
            fine_weights = torch.load(render_weights_path, map_location='cpu')
        except Exception as e:
            print(f"âŒ åŠ è½½æƒé‡å¤±è´¥: {e}")
            return sr_img, 0
        
        # SRå›¾åƒå°ºå¯¸
        sr_h, sr_w = sr_img.shape[:2]
        sr_tile_h, sr_tile_w = sr_h // self.tile_size, sr_w // self.tile_size
        
        # Fineå›¾åƒå°ºå¯¸ (åº”è¯¥æ˜¯SRçš„ä¸€åŠ)
        fine_h, fine_w = fine_weights.shape[:2]
        fine_tile_size = self.fine_tile_size  # 16x16
        fine_tile_h, fine_tile_w = fine_h // fine_tile_size, fine_w // fine_tile_size
        
        # ç¡®ä¿tileæ•°é‡åŒ¹é… (åº”è¯¥ç›¸ç­‰ï¼Œå› ä¸º2å€ä¸Šé‡‡æ ·)
        assert sr_tile_h == fine_tile_h and sr_tile_w == fine_tile_w, \
            f"Tileæ•°é‡ä¸åŒ¹é…: SR {sr_tile_h}x{sr_tile_w} vs Fine {fine_tile_h}x{fine_tile_w}"
        
        hybrid_img = sr_img.copy()
        replaced_tiles = 0
        tile_scores = []
        
        # é€tileåˆ†æ (åŒæ—¶å¤„ç†fineå’ŒSRå¯¹åº”çš„tiles)
        for i in range(fine_tile_h):
            for j in range(fine_tile_w):
                # Fineå›¾åƒä¸­çš„tileåæ ‡ (16x16)
                fine_h_start = i * fine_tile_size
                fine_h_end = (i + 1) * fine_tile_size
                fine_w_start = j * fine_tile_size  
                fine_w_end = (j + 1) * fine_tile_size
                
                # SRå›¾åƒä¸­å¯¹åº”çš„tileåæ ‡ (32x32)
                sr_h_start = i * self.tile_size
                sr_h_end = (i + 1) * self.tile_size
                sr_w_start = j * self.tile_size
                sr_w_end = (j + 1) * self.tile_size
                
                # ä»fineæƒé‡ä¸­æå–å¯¹åº”çš„tile
                fine_tile_weights = fine_weights[fine_h_start:fine_h_end, fine_w_start:fine_w_end, :]
                
                
                h_start = i * self.fine_tile_size
                h_end = (i + 1) * self.fine_tile_size
                w_start = j * self.fine_tile_size
                w_end = (j + 1) * self.fine_tile_size
                
                fine_tile = fine_img[h_start:h_end, w_start:w_end]
                confidence_score, threshold = self.extract_volume_rendering_confidence(fine_tile_weights, fine_tile)
                tile_scores.append(confidence_score)
                
                # æ›¿æ¢å†³ç­–: å¦‚æœç½®ä¿¡åº¦é«˜(ä¸ç¡®å®šæ€§å¤§)ï¼Œåˆ™æ›¿æ¢SR tile
                if confidence_score > threshold:
                    hybrid_img[sr_h_start:sr_h_end, sr_w_start:sr_w_end] = \
                        org_img[sr_h_start:sr_h_end, sr_w_start:sr_w_end]
                    replaced_tiles += 1
        
        replacement_ratio = replaced_tiles / (fine_tile_h * fine_tile_w)
        
        return hybrid_img, replaced_tiles
    
    def random_replacement_method(self, sr_img, org_img, num_tiles_to_replace):
        """éšæœºæ›¿æ¢æŒ‡å®šæ•°é‡çš„tiles"""
        h, w = sr_img.shape[:2]
        tile_h, tile_w = h // self.tile_size, w // self.tile_size
        total_tiles = tile_h * tile_w
        
        # éšæœºé€‰æ‹©è¦æ›¿æ¢çš„tiles
        replace_indices = np.random.choice(total_tiles, 
                                         min(num_tiles_to_replace, total_tiles), 
                                         replace=False)
        
        hybrid_img = sr_img.copy()
        replaced_tiles = 0
        
        for idx in replace_indices:
            i = idx // tile_w
            j = idx % tile_w
            h_start, h_end = i * self.tile_size, (i + 1) * self.tile_size
            w_start, w_end = j * self.tile_size, (j + 1) * self.tile_size
            
            hybrid_img[h_start:h_end, w_start:w_end] = org_img[h_start:h_end, w_start:w_end]
            replaced_tiles += 1
        
        return hybrid_img, replaced_tiles
    
    def canny_highres_method(self, sr_img, org_img, threshold=None):
        """é«˜åˆ†è¾¨ç‡Cannyè¾¹ç¼˜æ£€æµ‹æ–¹æ³•"""
        if threshold is None:
            threshold = self.canny_threshold
            
        h, w = sr_img.shape[:2]
        tile_h, tile_w = h // self.tile_size, w // self.tile_size
        
        hybrid_img = sr_img.copy()
        replaced_tiles = 0
        
        for i in range(tile_h):
            for j in range(tile_w):
                h_start, h_end = i * self.tile_size, (i + 1) * self.tile_size
                w_start, w_end = j * self.tile_size, (j + 1) * self.tile_size
                
                sr_tile = sr_img[h_start:h_end, w_start:w_end]
                edge_score = self.extract_edge_score_canny(sr_tile)
                
                if edge_score > threshold:
                    hybrid_img[h_start:h_end, w_start:w_end] = org_img[h_start:h_end, w_start:w_end]
                    replaced_tiles += 1
        
        return hybrid_img, replaced_tiles
    
    def canny_lowres_method(self, fine_img, sr_img, org_img, threshold=None):
        """ä½åˆ†è¾¨ç‡Cannyè¾¹ç¼˜æ£€æµ‹æ–¹æ³•"""
        if threshold is None:
            threshold = self.canny_threshold_lowres
            
        # åœ¨fineåˆ†è¾¨ç‡ä¸Šè¿›è¡Œåˆ†æ
        h_fine, w_fine = fine_img.shape[:2]
        tile_h, tile_w = h_fine // self.fine_tile_size, w_fine // self.fine_tile_size
        
        # åˆ›å»ºfineåˆ†è¾¨ç‡çš„æ©ç 
        fine_mask = np.zeros((h_fine, w_fine), dtype=bool)
        replaced_tiles = 0
        
        for i in range(tile_h):
            for j in range(tile_w):
                h_start = i * self.fine_tile_size
                h_end = (i + 1) * self.fine_tile_size
                w_start = j * self.fine_tile_size
                w_end = (j + 1) * self.fine_tile_size
                
                fine_tile = fine_img[h_start:h_end, w_start:w_end]
                edge_score = self.extract_edge_score_canny(fine_tile)
                
                if edge_score > threshold:
                    fine_mask[h_start:h_end, w_start:w_end] = True
                    replaced_tiles += 1
        
        # å°†æ©ç ä¸Šé‡‡æ ·åˆ°SRåˆ†è¾¨ç‡
        sr_mask = cv2.resize(
            fine_mask.astype(np.uint8), 
            (sr_img.shape[1], sr_img.shape[0]), 
            interpolation=cv2.INTER_NEAREST
        ).astype(bool)
        
        # åœ¨SRå›¾åƒä¸Šåº”ç”¨æ©ç 
        hybrid_img = sr_img.copy()
        hybrid_img[sr_mask] = org_img[sr_mask]
        
        return hybrid_img, replaced_tiles
    
    def test_single_image(self, scene, img_idx):
        """æµ‹è¯•å•å¼ å›¾åƒçš„æ‰€æœ‰æ–¹æ³•"""
        results = {
            'scene': scene,
            'img_idx': img_idx,
            'sr_psnr': 0,
            'total_tiles': 0,
            'random_max_psnr': 0,
            'random_max_improvement': 0,
            'random_max_tiles': 0,
            'canny_highres_psnr': 0,
            'canny_highres_improvement': 0,
            'canny_highres_tiles': 0,
            'canny_lowres_psnr': 0,
            'canny_lowres_improvement': 0,
            'canny_lowres_tiles': 0,
            'volume_confidence_psnr': 0,
            'volume_confidence_improvement': 0,
            'volume_confidence_tiles': 0,
            'depth_discontinuity_psnr': 0,
            'depth_discontinuity_improvement': 0,
            'depth_discontinuity_tiles': 0,
        }
        
        # åŠ è½½å›¾åƒ
        org_path = self.eval_llff_path / scene / f"{img_idx}_pred_fine.png"
        sr_path = self.eval_llff_sr_path / scene / f"{img_idx}_pred_sr.png"
        fine_path = self.eval_llff_sr_path / scene / f"{img_idx}_pred_fine.png"
        gt_path = self.eval_llff_sr_path / scene / f"{img_idx}_gt_rgb_hr.png" # important
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not all(p.exists() for p in [org_path, sr_path, fine_path, gt_path]):
            return None
        
        org_img = np.array(Image.open(org_path))
        sr_img = np.array(Image.open(sr_path))
        fine_img = np.array(Image.open(fine_path))
        gt_img = np.array(Image.open(gt_path))
        
        # è°ƒæ•´GTå›¾åƒå°ºå¯¸ä»¥åŒ¹é…SRè¾“å‡º
        if gt_img.shape != sr_img.shape:
            gt_img = cv2.resize(gt_img, (sr_img.shape[1], sr_img.shape[0]))
        
        # è®¡ç®—æ€»tileæ•°
        h, w = sr_img.shape[:2]
        tile_h, tile_w = h // self.tile_size, w // self.tile_size
        total_tiles = tile_h * tile_w
        results['total_tiles'] = total_tiles
        
        # è®¡ç®—åŸå§‹SR PSNR
        sr_psnr = psnr(gt_img, sr_img)
        results['sr_psnr'] = sr_psnr
        
        # 2. é«˜åˆ†è¾¨ç‡Cannyæ–¹æ³•
        canny_hr_img, canny_hr_tiles = self.canny_highres_method(sr_img, org_img)
        canny_hr_psnr = psnr(gt_img, canny_hr_img)
        results['canny_highres_psnr'] = canny_hr_psnr
        results['canny_highres_improvement'] = canny_hr_psnr - sr_psnr
        results['canny_highres_tiles'] = canny_hr_tiles
        
        # 3. ä½åˆ†è¾¨ç‡Cannyæ–¹æ³•
        canny_lr_img, canny_lr_tiles = self.canny_lowres_method(fine_img, sr_img, org_img)
        canny_lr_psnr = psnr(gt_img, canny_lr_img)
        results['canny_lowres_psnr'] = canny_lr_psnr
        results['canny_lowres_improvement'] = canny_lr_psnr - sr_psnr
        results['canny_lowres_tiles'] = canny_lr_tiles
        
        # 4. ä½“æ¸²æŸ“ç½®ä¿¡åº¦æ–¹æ³•
        weights_path = Path(f"/home/ytanaz/access/IBRNet/test_sr/data/datasets/{scene}") / f"render_weights_{img_idx}_n48.pt"
        weights_path = Path(f"/home/ytanaz/access/IBRNet/test_sr/data/datasets/{scene}") / f"render_sigmas_{img_idx}_n48.pt"
        depth_path = Path(f"/home/ytanaz/access/IBRNet/test_sr/data/datasets/{scene}") / f"render_depths_{img_idx}_n48.pt"
        if weights_path.exists():
            volume_img, volume_tiles = self.volume_rendering_confidence_method(sr_img, fine_img, org_img, str(weights_path))
            volume_psnr = psnr(gt_img, volume_img)
            results['volume_confidence_psnr'] = volume_psnr
            results['volume_confidence_improvement'] = volume_psnr - sr_psnr
            results['volume_confidence_tiles'] = volume_tiles
        else:
            print(f"âš ï¸ æœªæ‰¾åˆ°æƒé‡æ–‡ä»¶: {weights_path}")
            results['volume_confidence_psnr'] = sr_psnr
            results['volume_confidence_improvement'] = 0.0
            results['volume_confidence_tiles'] = 0
        
        # 5. æ·±åº¦ä¸è¿ç»­æ€§æ–¹æ³•
        if depth_path.exists():
            depth_img, depth_tiles = self.depth_discontinuity_method(sr_img, fine_img, org_img, str(depth_path))
            depth_psnr = psnr(gt_img, depth_img)
            results['depth_discontinuity_psnr'] = depth_psnr
            results['depth_discontinuity_improvement'] = depth_psnr - sr_psnr
            results['depth_discontinuity_tiles'] = depth_tiles
        else:
            print(f"âš ï¸ æœªæ‰¾åˆ°æ·±åº¦æ–‡ä»¶: {depth_path}")
            results['depth_discontinuity_psnr'] = sr_psnr
            results['depth_discontinuity_improvement'] = 0.0
            results['depth_discontinuity_tiles'] = 0
        
        # 6. GACM (å‡ ä½•æ„ŸçŸ¥å¤æ‚åº¦æŒ‡æ ‡) æ–¹æ³•
        if depth_path.exists():
            gacm_img, gacm_tiles = self.gacm_method(sr_img, org_img, str(depth_path))
            gacm_psnr = psnr(gt_img, gacm_img)
            results['gacm_psnr'] = gacm_psnr
            results['gacm_improvement'] = gacm_psnr - sr_psnr
            results['gacm_tiles'] = gacm_tiles
        else:
            print(f"âš ï¸ æœªæ‰¾åˆ°æ·±åº¦æ–‡ä»¶: {depth_path}")
            results['gacm_psnr'] = sr_psnr
            results['gacm_improvement'] = 0.0
            results['gacm_tiles'] = 0

        # 1. éšæœºæ›¿æ¢ï¼ˆä½¿ç”¨æ‰€æœ‰æ–¹æ³•ä¸­çš„æœ€å¤§tileæ•°ä½œä¸ºåŸºçº¿ï¼‰
        max_tiles = max(canny_hr_tiles, canny_lr_tiles, 
                        results['volume_confidence_tiles'], 
                        results['depth_discontinuity_tiles'],
                        results['gacm_tiles'])
        random_img, _ = self.random_replacement_method(sr_img, org_img, max_tiles)
        random_psnr = psnr(gt_img, random_img)
        results['random_max_psnr'] = random_psnr
        results['random_max_improvement'] = random_psnr - sr_psnr
        results['random_max_tiles'] = max_tiles
            
        # except Exception as e:
        #     print(f"é”™è¯¯å¤„ç† {scene}/{img_idx}: {e}")
        #     return None
        
        return results
    
    def test_all_images(self):
        """æµ‹è¯•æ‰€æœ‰å›¾åƒ"""
        print("ğŸš€ å¼€å§‹æ‰¹é‡æµ‹è¯•æ‰€æœ‰å›¾åƒ...")
        
        # scenes = self.get_scenes(special_scene='horns')
        scenes = self.get_scenes()
        print(f"å‘ç°åœºæ™¯: {scenes}")
        
        all_results = []
        total_images = 0
        
        # ç»Ÿè®¡æ€»å›¾åƒæ•°
        for scene in scenes:
            scene_path = self.eval_llff_sr_path / scene
            if scene_path.exists():
                indices = self.get_image_indices(scene_path)
                total_images += len(indices)
        
        print(f"æ€»å…±éœ€è¦æµ‹è¯• {total_images} å¼ å›¾åƒ")
        
        # ä½¿ç”¨è¿›åº¦æ¡æµ‹è¯•æ‰€æœ‰å›¾åƒ
        with tqdm(total=total_images, desc="æµ‹è¯•è¿›åº¦") as pbar:
            for scene in scenes:
                scene_path = self.eval_llff_sr_path / scene
                if not scene_path.exists():
                    continue
                
                indices = self.get_image_indices(scene_path)
                print(f"\næ­£åœ¨æµ‹è¯•åœºæ™¯ {scene}: {len(indices)} å¼ å›¾åƒ")
                
                for img_idx in indices:
                    result = self.test_single_image(scene, img_idx)
                    if result is not None:
                        all_results.append(result)
                    pbar.update(1)
        
        return all_results
    
    def analyze_results(self, results):
        """åˆ†ææµ‹è¯•ç»“æœ"""
        df = pd.DataFrame(results)
        
        print("\nğŸ“Š æ‰¹é‡æµ‹è¯•ç»“æœåˆ†æ")
        print("="*70)
        
        # æ€»ä½“ç»Ÿè®¡
        print(f"æµ‹è¯•å›¾åƒæ€»æ•°: {len(df)}")
        print(f"æµ‹è¯•åœºæ™¯: {df['scene'].unique()}")
        
        # è®¡ç®—å¹³å‡å€¼
        avg_results = {
            'SRåŸå§‹PSNR': df['sr_psnr'].mean(),
            'éšæœºæœ€å¤§tiles': df['random_max_improvement'].mean(),
            'Cannyé«˜åˆ†è¾¨ç‡': df['canny_highres_improvement'].mean(),
            'Cannyä½åˆ†è¾¨ç‡': df['canny_lowres_improvement'].mean(),
            'ä½“æ¸²æŸ“ç½®ä¿¡åº¦': df['volume_confidence_improvement'].mean(),
            'æ·±åº¦ä¸è¿ç»­æ€§': df['depth_discontinuity_improvement'].mean(),
            'GACM': df['gacm_improvement'].mean()
        }
        
        print(f"\nğŸ“ˆ å¹³å‡PSNRæå‡ (dB):")
        print(f"{'æ–¹æ³•':<20} {'PSNRæå‡':<10} {'æ ‡å‡†å·®':<10}")
        print("-" * 45)
        print(f"{'éšæœºæœ€å¤§tiles':<20} {avg_results['éšæœºæœ€å¤§tiles']:<9.3f} {df['random_max_improvement'].std():<9.3f}")
        print(f"{'Cannyé«˜åˆ†è¾¨ç‡':<20} {avg_results['Cannyé«˜åˆ†è¾¨ç‡']:<9.3f} {df['canny_highres_improvement'].std():<9.3f}")
        print(f"{'Cannyä½åˆ†è¾¨ç‡':<20} {avg_results['Cannyä½åˆ†è¾¨ç‡']:<9.3f} {df['canny_lowres_improvement'].std():<9.3f}")
        print(f"{'ä½“æ¸²æŸ“ç½®ä¿¡åº¦':<20} {avg_results['ä½“æ¸²æŸ“ç½®ä¿¡åº¦']:<9.3f} {df['volume_confidence_improvement'].std():<9.3f}")
        print(f"{'æ·±åº¦ä¸è¿ç»­æ€§':<20} {avg_results['æ·±åº¦ä¸è¿ç»­æ€§']:<9.3f} {df['depth_discontinuity_improvement'].std():<9.3f}")
        print(f"{'GACM':<20} {avg_results['GACM']:<9.3f} {df['gacm_improvement'].std():<9.3f}")
        
        # æ›¿æ¢tilesç»Ÿè®¡
        print(f"\nğŸ”§ å¹³å‡æ›¿æ¢Tilesæ•°:")
        avg_total_tiles = df['total_tiles'].mean()
        print(f"å¹³å‡æ€»tilesæ•°: {avg_total_tiles:.0f} tiles")
        print(f"éšæœºæ›¿æ¢: {df['random_max_tiles'].mean():.1f} tiles (åŸºçº¿)")
        print(f"Cannyé«˜åˆ†è¾¨ç‡: {df['canny_highres_tiles'].mean():.1f} tiles")
        print(f"Cannyä½åˆ†è¾¨ç‡: {df['canny_lowres_tiles'].mean():.1f} tiles")
        print(f"ä½“æ¸²æŸ“ç½®ä¿¡åº¦: {df['volume_confidence_tiles'].mean():.1f} tiles")
        print(f"æ·±åº¦ä¸è¿ç»­æ€§: {df['depth_discontinuity_tiles'].mean():.1f} tiles")
        print(f"GACM: {df['gacm_tiles'].mean():.1f} tiles")
        
        # æ›¿æ¢æ¯”ä¾‹ç»Ÿè®¡
        print(f"\nğŸ“ æ›¿æ¢æ¯”ä¾‹(æ›¿æ¢tiles/æ€»tiles):")
        print(f"éšæœºæ›¿æ¢: {df['random_max_tiles'].mean()/avg_total_tiles:.1%}")
        print(f"Cannyé«˜åˆ†è¾¨ç‡: {df['canny_highres_tiles'].mean()/avg_total_tiles:.1%}")
        print(f"Cannyä½åˆ†è¾¨ç‡: {df['canny_lowres_tiles'].mean()/avg_total_tiles:.1%}")
        print(f"ä½“æ¸²æŸ“ç½®ä¿¡åº¦: {df['volume_confidence_tiles'].mean()/avg_total_tiles:.1%}")
        print(f"æ·±åº¦ä¸è¿ç»­æ€§: {df['depth_discontinuity_tiles'].mean()/avg_total_tiles:.1%}")
        print(f"GACM: {df['gacm_tiles'].mean()/avg_total_tiles:.1%}")
        
        # æŒ‰åœºæ™¯åˆ†æ
        print(f"\nğŸ¬ æŒ‰åœºæ™¯åˆ†æ:")
        scene_columns = {
            'sr_psnr': 'mean',
            'total_tiles': 'mean',
            'random_max_improvement': 'mean',
            'random_max_tiles': 'mean',
            'canny_highres_improvement': 'mean',
            'canny_lowres_improvement': 'mean',
            'canny_highres_tiles': 'mean',
            'canny_lowres_tiles': 'mean',
            'volume_confidence_improvement': 'mean',
            'volume_confidence_tiles': 'mean',
            'depth_discontinuity_improvement': 'mean',
            'depth_discontinuity_tiles': 'mean',
        }
        
        scene_stats = df.groupby('scene').agg(scene_columns)
        
        for scene in scene_stats.index:
            stats = scene_stats.loc[scene]
            total_tiles = stats['total_tiles']
            print(f"\n{scene}:")
            print(f"  å¹³å‡SR PSNR: {stats['sr_psnr']:.2f} dB")
            print(f"  æ€»tilesæ•°: {total_tiles:.0f} tiles")
            print(f"  éšæœºæœ€å¤§tiles: +{stats['random_max_improvement']:.3f} dB ({stats['random_max_tiles']:.1f} tiles, {stats['random_max_tiles']/total_tiles:.1%})")
            print(f"  Cannyé«˜åˆ†è¾¨ç‡: +{stats['canny_highres_improvement']:.3f} dB ({stats['canny_highres_tiles']:.1f} tiles, {stats['canny_highres_tiles']/total_tiles:.1%})")
            print(f"  Cannyä½åˆ†è¾¨ç‡: +{stats['canny_lowres_improvement']:.3f} dB ({stats['canny_lowres_tiles']:.1f} tiles, {stats['canny_lowres_tiles']/total_tiles:.1%})")
            print(f"  ä½“æ¸²æŸ“ç½®ä¿¡åº¦: +{stats['volume_confidence_improvement']:.3f} dB ({stats['volume_confidence_tiles']:.1f} tiles, {stats['volume_confidence_tiles']/total_tiles:.1%})")
            print(f"  æ·±åº¦ä¸è¿ç»­æ€§: +{stats['depth_discontinuity_improvement']:.3f} dB ({stats['depth_discontinuity_tiles']:.1f} tiles, {stats['depth_discontinuity_tiles']/total_tiles:.1%})")
        
        return df, avg_results
    
    def save_results(self, df, avg_results):
        """ä¿å­˜ç»“æœ"""
        output_dir = Path("/home/ytanaz/access/IBRNet/test_sr/results/batch_test")
        output_dir.mkdir(exist_ok=True)
        
        # ä¿å­˜è¯¦ç»†CSV
        csv_path = output_dir / "batch_test_detailed_results.csv"
        df.to_csv(csv_path, index=False)
        print(f"\nğŸ’¾ è¯¦ç»†ç»“æœä¿å­˜åˆ°: {csv_path}")
        
        # ä¿å­˜æ€»ç»“æŠ¥å‘Š
        report_path = output_dir / "batch_test_summary_report.txt"
        with open(report_path, 'w') as f:
            f.write("=== LLFFæ•°æ®é›†æ‰¹é‡æµ‹è¯•æ€»ç»“æŠ¥å‘Š ===\n\n")
            f.write(f"æµ‹è¯•æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"æµ‹è¯•å›¾åƒæ€»æ•°: {len(df)}\n")
            f.write(f"æµ‹è¯•åœºæ™¯: {', '.join(df['scene'].unique())}\n\n")
            
            f.write("å¹³å‡PSNRæå‡ç»“æœ:\n")
            f.write(f"éšæœºæœ€å¤§tilesæ›¿æ¢: +{avg_results['éšæœºæœ€å¤§tiles']:.3f} dB\n")
            f.write(f"Cannyé«˜åˆ†è¾¨ç‡æ–¹æ³•: +{avg_results['Cannyé«˜åˆ†è¾¨ç‡']:.3f} dB\n")
            f.write(f"Cannyä½åˆ†è¾¨ç‡æ–¹æ³•: +{avg_results['Cannyä½åˆ†è¾¨ç‡']:.3f} dB\n")
            
            # æ·»åŠ æ›¿æ¢æ¯”ä¾‹ä¿¡æ¯
            avg_total_tiles = df['total_tiles'].mean()
            f.write(f"\næ›¿æ¢æ¯”ä¾‹ç»Ÿè®¡(å¹³å‡æ€»tiles: {avg_total_tiles:.0f}):\n")
            f.write(f"éšæœºæ›¿æ¢: {df['random_max_tiles'].mean()/avg_total_tiles:.1%}\n")
            f.write(f"Cannyé«˜åˆ†è¾¨ç‡: {df['canny_highres_tiles'].mean()/avg_total_tiles:.1%}\n")
            f.write(f"Cannyä½åˆ†è¾¨ç‡: {df['canny_lowres_tiles'].mean()/avg_total_tiles:.1%}\n")
            
            f.write("\nå…³é”®ç»“è®º:\n")
            canny_hr_vs_random = avg_results['Cannyé«˜åˆ†è¾¨ç‡'] / avg_results['éšæœºæœ€å¤§tiles']
            canny_lr_vs_random = avg_results['Cannyä½åˆ†è¾¨ç‡'] / avg_results['éšæœºæœ€å¤§tiles']
            f.write(f"Cannyé«˜åˆ†è¾¨ç‡ vs éšæœº: {canny_hr_vs_random:.2f}å€æ•ˆæœ\n")
            f.write(f"Cannyä½åˆ†è¾¨ç‡ vs éšæœº: {canny_lr_vs_random:.2f}å€æ•ˆæœ\n")
            
            f.write(f"ä½åˆ†è¾¨ç‡æ–¹æ³•è®¡ç®—é‡å‡å°‘: 75%\n")
        
        print(f"ğŸ“‹ æ€»ç»“æŠ¥å‘Šä¿å­˜åˆ°: {report_path}")
        
        # ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
        self.create_visualization(df, output_dir)
    
    def create_visualization(self, df, output_dir):
        """Create visualization charts"""
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))
        
        # 1. PSNR improvement comparison
        methods = ['Random Max Tiles', 'Canny High Resolution', 'Canny Low Resolution']
        improvements = [
            df['random_max_improvement'].mean(),
            df['canny_highres_improvement'].mean(),
            df['canny_lowres_improvement'].mean()
        ]
        
        colors = ['gray', 'blue', 'red', 'green', 'orange'][:len(methods)]
        ax1.bar(methods, improvements, color=colors)
        ax1.set_ylabel('Average PSNR Improvement (dB)')
        ax1.set_title('PSNR Improvement Comparison of Different Methods')
        ax1.grid(True, alpha=0.3)
        ax1.tick_params(axis='x', rotation=45)
        
        # 2. PSNR improvement by scene
        scene_columns = {
            'canny_highres_improvement': 'mean',
            'canny_lowres_improvement': 'mean'
        }
        
        scene_stats = df.groupby('scene').agg(scene_columns)
        
        x = np.arange(len(scene_stats.index))
        width = 0.15 if len(scene_columns) > 2 else 0.35
        
        bars = []
        labels = ['Canny High Res', 'Canny Low Res']
        colors = ['blue', 'red']
        
        bars.append(ax2.bar(x - width, scene_stats['canny_highres_improvement'], width, 
                label='Canny High Resolution', color='blue', alpha=0.7))
        bars.append(ax2.bar(x, scene_stats['canny_lowres_improvement'], width,
                label='Canny Low Resolution', color='red', alpha=0.7))
        
        ax2.set_xlabel('Scene')
        ax2.set_ylabel('Average PSNR Improvement (dB)')
        ax2.set_title('PSNR Improvement Comparison by Scene')
        ax2.set_xticks(x)
        ax2.set_xticklabels(scene_stats.index, rotation=45)
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        
        # 3. Number of replaced tiles comparison
        tile_methods = ['Canny High Res', 'Canny Low Res']
        avg_tiles = [df['canny_highres_tiles'].mean(), df['canny_lowres_tiles'].mean()]
        colors = ['blue', 'red']
        
        ax3.bar(tile_methods, avg_tiles, color=colors, alpha=0.7)
        ax3.set_ylabel('Average Number of Replaced Tiles')
        ax3.set_title('Comparison of Average Number of Replaced Tiles')
        ax3.grid(True, alpha=0.3)
        ax3.tick_params(axis='x', rotation=45)
        
        # 4. PSNR improvement distribution
        ax4.hist(df['canny_highres_improvement'], bins=20, alpha=0.7, 
                label='Canny High Resolution', color='blue')
        ax4.hist(df['canny_lowres_improvement'], bins=20, alpha=0.7,
                label='Canny Low Resolution', color='red')
        ax4.set_xlabel('PSNR Improvement (dB)')
        ax4.set_ylabel('Frequency')
        ax4.set_title('PSNR Improvement Distribution')
        ax4.legend()
        ax4.grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        # Save the chart
        chart_path = output_dir / "batch_test_analysis_charts.png"
        plt.savefig(chart_path, dpi=300, bbox_inches='tight')
        plt.close()

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ” LLFFæ•°æ®é›†æ‰¹é‡æµ‹è¯•å¼€å§‹")
    print("="*70)
    
    # åˆ›å»ºæµ‹è¯•å™¨
    tester = BatchTileReplacementTester()
    
    # è®¾ç½®éšæœºç§å­ç¡®ä¿å¯é‡å¤æ€§
    np.random.seed(42)
    
    # æ‰§è¡Œæ‰¹é‡æµ‹è¯•
    start_time = time.time()
    results = tester.test_all_images()
    end_time = time.time()
    
    if not results:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„æµ‹è¯•ç»“æœ")
        return
    
    print(f"\nâ±ï¸ æµ‹è¯•å®Œæˆï¼Œè€—æ—¶: {end_time - start_time:.1f} ç§’")
    
    # åˆ†æç»“æœ
    df, avg_results = tester.analyze_results(results)
    
    # ä¿å­˜ç»“æœ
    tester.save_results(df, avg_results)

if __name__ == "__main__":
    main()
