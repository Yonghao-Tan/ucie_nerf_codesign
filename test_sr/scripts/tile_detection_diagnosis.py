#!/usr/bin/env python3
"""
Tileæ£€æµ‹æ–¹æ³•è¯Šæ–­å·¥å…·
åˆ†ææŸå¤±æœ€å¤§çš„tilesï¼Œçœ‹çœ‹å„ä¸ªæ–¹æ³•æ˜¯å¦èƒ½æ­£ç¡®è¯†åˆ«å‡ºè¿™äº›éœ€è¦æ›¿æ¢çš„tiles

ä½¿ç”¨æ–¹æ³•:
python tile_detection_diagnosis.py
"""

import os
import sys
import numpy as np
import cv2
from PIL import Image
import matplotlib.pyplot as plt
import torch
import torch.nn.functional as F
import pandas as pd
from pathlib import Path

# æ·»åŠ å½“å‰è„šæœ¬ç›®å½•åˆ°è·¯å¾„
sys.path.append('/home/ytanaz/access/IBRNet/test_sr/scripts')

# è®¾ç½®matplotlibä½¿ç”¨è‹±æ–‡ï¼Œé¿å…ä¸­æ–‡å­—ä½“é—®é¢˜
plt.rcParams['font.family'] = 'DejaVu Sans'
plt.rcParams['axes.unicode_minus'] = False

def load_image(img_path):
    """åŠ è½½å›¾ç‰‡å¹¶è½¬æ¢ä¸ºnumpyæ•°ç»„ï¼Œè¿”å› (H, W, 3) çš„float32æ•°ç»„ï¼Œå€¼èŒƒå›´[0, 1]"""
    img = Image.open(img_path).convert('RGB')
    img = np.array(img).astype(np.float32) / 255.0
    return img

def calculate_psnr(pred_img, gt_img):
    """è®¡ç®—PSNR"""
    if pred_img.shape != gt_img.shape:
        raise ValueError(f"å›¾ç‰‡å°ºå¯¸ä¸åŒ¹é…: {pred_img.shape} vs {gt_img.shape}")
    
    mse = np.mean((pred_img - gt_img) ** 2)
    if mse == 0:
        return float('inf')
    
    max_pixel = 1.0
    psnr = 20 * np.log10(max_pixel / np.sqrt(mse))
    return psnr

def calculate_tile_wise_psnr(pred_img, gt_img, tile_size=32):
    """è®¡ç®—æ¯ä¸ªtileçš„PSNR"""
    H, W, C = pred_img.shape
    
    h_tiles = (H + tile_size - 1) // tile_size
    w_tiles = (W + tile_size - 1) // tile_size
    
    tile_psnr_map = np.zeros((h_tiles, w_tiles))
    tile_coords = []
    
    for i in range(h_tiles):
        for j in range(w_tiles):
            h_start = i * tile_size
            h_end = min(h_start + tile_size, H)
            w_start = j * tile_size
            w_end = min(w_start + tile_size, W)
            
            pred_tile = pred_img[h_start:h_end, w_start:w_end, :]
            gt_tile = gt_img[h_start:h_end, w_start:w_end, :]
            
            tile_psnr = calculate_psnr(pred_tile, gt_tile)
            tile_psnr_map[i, j] = tile_psnr
            
            tile_coords.append({
                'tile_id': (i, j),
                'coords': (h_start, h_end, w_start, w_end),
                'psnr': tile_psnr
            })
    
    return tile_psnr_map, tile_coords

def extract_canny_high_res(fine_img, threshold=0.160):
    """Cannyé«˜åˆ†è¾¨ç‡æ–¹æ³• - åœ¨fineåˆ†è¾¨ç‡å›¾åƒä¸Šæå–è¾¹ç¼˜"""
    fine_gray = cv2.cvtColor((fine_img * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)
    edges = cv2.Canny(fine_gray, 50, 150)
    edge_density = edges.sum() / (edges.size * 255)
    return edge_density

def extract_canny_low_res(sr_img, threshold=0.250):
    """Cannyä½åˆ†è¾¨ç‡æ–¹æ³• - åœ¨SRåˆ†è¾¨ç‡å›¾åƒä¸Šæå–è¾¹ç¼˜"""
    sr_gray = cv2.cvtColor((sr_img * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)
    edges = cv2.Canny(sr_gray, 50, 150)
    edge_density = edges.sum() / (edges.size * 255)
    return edge_density

def extract_volume_rendering_confidence(render_weights_path):
    """ä½“æ¸²æŸ“ç½®ä¿¡åº¦æ–¹æ³•"""
    weights = torch.load(render_weights_path, map_location='cpu')
    
    dcm_score, need_full_render = density_complexity_metric(weights.numpy(), 
                    sigma_threshold=0.5,
                    grad_threshold=0.3,
                    curvature_threshold=0.2)
    if len(weights.shape) == 3:
    #     H, W, n_samples = weights.shape
    #     # è®¡ç®—æ¯ä¸ªåƒç´ çš„æ¸²æŸ“ç½®ä¿¡åº¦ - ä¿®å¤NaNé—®é¢˜
    #     weights_safe = torch.clamp(weights, min=1e-8)  # é¿å…log(0)
    #     confidence_map = torch.sum(weights_safe * torch.log(weights_safe + 1e-8), dim=-1)
    #     confidence_map = -confidence_map  # ç†µè¶Šå°ï¼Œç½®ä¿¡åº¦è¶Šé«˜
        
    #     # å®‰å…¨å½’ä¸€åŒ–
    #     conf_min = confidence_map.min()
    #     conf_max = confidence_map.max()
    #     if conf_max > conf_min:
    #         confidence_map = (confidence_map - conf_min) / (conf_max - conf_min + 1e-8)
    #     else:
    #         confidence_map = torch.zeros_like(confidence_map)
        
    #     return confidence_map.numpy()
        print(dcm_score)
        return dcm_score
    else:
        print(f"è­¦å‘Šï¼šä½“æ¸²æŸ“æƒé‡ç»´åº¦ä¸åŒ¹é…ï¼š{weights.shape}")
        return None

def extract_depth_discontinuity_score(depth_map_path):
    """æ·±åº¦ä¸è¿ç»­æ€§æ–¹æ³•"""
    try:
        depth_map = torch.load(depth_map_path, map_location='cpu')
        if len(depth_map.shape) == 2:
            # å®‰å…¨å½’ä¸€åŒ–æ·±åº¦å›¾
            depth_min = depth_map.min()
            depth_max = depth_map.max()
            if depth_max > depth_min:
                depth_normalized = (depth_map - depth_min) / (depth_max - depth_min + 1e-8)
            else:
                depth_normalized = torch.zeros_like(depth_map)
            
            # è®¡ç®—æ·±åº¦æ¢¯åº¦
            sobel_x = torch.tensor([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], dtype=torch.float32)
            sobel_y = sobel_x.T
            
            grad_x = F.conv2d(depth_normalized[None, None], sobel_x[None, None], padding=1)[0, 0]
            grad_y = F.conv2d(depth_normalized[None, None], sobel_y[None, None], padding=1)[0, 0]
            
            gradient_magnitude = torch.sqrt(grad_x**2 + grad_y**2 + 1e-8)
            return gradient_magnitude.numpy()
        else:
            print(f"è­¦å‘Šï¼šæ·±åº¦å›¾ç»´åº¦ä¸åŒ¹é…ï¼š{depth_map.shape}")
            return None
    except Exception as e:
        print(f"è­¦å‘Šï¼šæ— æ³•åŠ è½½æ·±åº¦å›¾ï¼š{e}")
        return None

def density_complexity_metric(tile_sigma, 
                             sigma_threshold=0.5,
                             grad_threshold=0.3,
                             curvature_threshold=0.2):
    """
    çº¯å¯†åº¦åœºå¤æ‚åº¦æŒ‡æ ‡ï¼ˆDensity Complexity Metric, DCMï¼‰
    
    å‚æ•°:
        tile_sigma: [tile_size, tile_size, num_samples] 
                   å¯†åº¦åœºé‡‡æ ·å€¼ (sigma)ï¼Œæ²¿å…‰çº¿çš„é‡‡æ ·ç‚¹
        sigma_threshold: å¯†åº¦é˜ˆå€¼ (é»˜è®¤0.5)ï¼Œç”¨äºç­›é€‰è¡¨é¢åŒºåŸŸ
        grad_threshold: æ¢¯åº¦é˜ˆå€¼ (é»˜è®¤0.3)ï¼Œç”¨äºç­›é€‰é«˜å˜åŒ–åŒºåŸŸ
        curvature_threshold: æ›²ç‡é˜ˆå€¼ (é»˜è®¤0.2)
    
    è¿”å›:
        dcm_score: å¯†åº¦å¤æ‚åº¦å¾—åˆ† (0~1)
        need_full_render: æ˜¯å¦éœ€è¦å®Œæ•´NeRFæ¸²æŸ“ (True/False)
    """
    # 1. æå–è¡¨é¢åŒºåŸŸï¼ˆé«˜å¯†åº¦åŒºåŸŸï¼‰
    surface_mask = (tile_sigma > sigma_threshold)  # [H, W, N]
    
    # 2. è®¡ç®—å¯†åº¦æ¢¯åº¦ï¼ˆæ²¿å…‰çº¿æ–¹å‘ï¼‰
    d_sigma = np.diff(tile_sigma, axis=-1)  # [H, W, N-1]
    grad_mag = np.abs(d_sigma)  # æ¢¯åº¦å¹…å€¼
    
    # 3. è®¡ç®—è¡¨é¢æ¢¯åº¦å¼ºåº¦ï¼ˆä»…è€ƒè™‘è¡¨é¢åŒºåŸŸï¼‰
    surface_grad = grad_mag * surface_mask[..., :-1]  # [H, W, N-1]
    avg_surface_grad = np.mean(surface_grad)
    
    # 4. è®¡ç®—è¡¨é¢æ›²ç‡ï¼ˆäºŒé˜¶å¯¼æ•°ï¼‰
    d2_sigma = np.diff(d_sigma, axis=-1)  # [H, W, N-2]
    curvature = np.abs(d2_sigma) * surface_mask[..., 2:]  # ä»…è¡¨é¢åŒºåŸŸ
    avg_curvature = np.mean(curvature)
    
    # 5. è®¡ç®—å¤šå±‚è¡¨é¢æŒ‡æ ‡ï¼ˆé˜²æ­¢è–„ç‰©ä½“æ¼æ£€ï¼‰
    layer_count = np.sum(surface_mask, axis=-1)  # æ¯åƒç´ çš„è¡¨é¢å±‚æ•°
    multi_layer_ratio = np.mean(layer_count >= 2)  # å¤šå±‚è¡¨é¢å æ¯”
    
    # 6. èåˆæŒ‡æ ‡ â†’ DCMå¾—åˆ†
    dcm_score = (
        0.5 * np.clip(avg_surface_grad / grad_threshold, 0, 1) +
        0.3 * np.clip(avg_curvature / curvature_threshold, 0, 1) +
        0.2 * multi_layer_ratio
    )
    
    # 7. å†³ç­–ï¼ˆé˜ˆå€¼å¯è°ƒï¼‰
    need_full_render = (dcm_score > 0.6)
    
    return dcm_score, need_full_render

def compute_gacm(tile_color, tile_depth, alpha=0.4, beta=0.3, gamma=0.3, tau_D_ratio=0.1, threshold=0.25):
    """
    è®¡ç®—å‡ ä½•æ„ŸçŸ¥å¤æ‚åº¦æŒ‡æ ‡ (GACM)
    
    å‚æ•°:
        tile_color: [32, 32, 3] é™é‡‡æ ·é¢œè‰²å›¾åƒ (torch.Tensor, 0~1)
        tile_depth: [32, 32] é™é‡‡æ ·æ·±åº¦å›¾ (torch.Tensor)
        alpha, beta, gamma: DD, SC, GAE çš„æƒé‡ (é»˜è®¤ 0.4, 0.3, 0.3)
        tau_D_ratio: æ·±åº¦æ¢¯åº¦é˜ˆå€¼æ¯”ä¾‹ (é»˜è®¤ 0.1 â†’ tau_D = 0.1 * max(G_D))
        threshold: æœ€ç»ˆå†³ç­–é˜ˆå€¼ (é»˜è®¤ 0.25)
    
    è¿”å›:
        gacm_score: å‡ ä½•å¤æ‚åº¦å¾—åˆ† (0~1)
        decision: bool (True=éœ€å®Œæ•´NeRF, False=å¯è¶…åˆ†)
    """
    # === Step 0: æ·±åº¦å›¾é¢„å¤„ç† (å…³é”®ï¼é¿å…å™ªå£°å¹²æ‰°) ===
    depth = tile_depth.clone()
    
    # æ£€æŸ¥æ·±åº¦å›¾æ˜¯å¦ä¸ºç©ºæˆ–æ— æ•ˆ
    if depth.numel() == 0:
        return 0.0, False
    
    # å½’ä¸€åŒ–æ·±åº¦åˆ° [0,1] (é€‚é…ä¸åŒåœºæ™¯å°ºåº¦)
    depth_min, depth_max = depth.min(), depth.max()
    if depth_max > depth_min:
        depth = (depth - depth_min) / (depth_max - depth_min + 1e-5)
    else:
        depth = torch.zeros_like(depth)
    
    # === Step 1: è®¡ç®—æ·±åº¦é©±åŠ¨çš„å‡ ä½•å¤æ‚åº¦ ===
    # 1.1 æ·±åº¦ä¸è¿ç»­æ€§ (Depth Discontinuity, DD)
    sobel_x = torch.tensor([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], dtype=torch.float32, device=depth.device)
    sobel_y = sobel_x.T
    
    if depth.dim() == 2 and depth.shape[0] > 2 and depth.shape[1] > 2:
        grad_x = torch.nn.functional.conv2d(depth[None, None], sobel_x[None, None], padding=1)[0,0]
        grad_y = torch.nn.functional.conv2d(depth[None, None], sobel_y[None, None], padding=1)[0,0]
        G_D = torch.sqrt(grad_x**2 + grad_y**2 + 1e-5)  # é¿å…é™¤é›¶
        DD_tile = G_D.mean().item()
    else:
        DD_tile = 0.0
        G_D = torch.zeros_like(depth)
    
    # 1.2 è¡¨é¢æ›²ç‡ (Surface Curvature, SC)
    if depth.dim() == 2 and depth.shape[0] > 2 and depth.shape[1] > 2:
        laplacian = torch.nn.functional.conv2d(
            depth[None, None], 
            torch.tensor([[0, 1, 0], [1, -4, 1], [0, 1, 0]], device=depth.device, dtype=torch.float32)[None, None],
            padding=1
        )[0,0]
        SC_tile = torch.abs(laplacian).mean().item()
    else:
        SC_tile = 0.0
    
    # === Step 2: è®¡ç®—å‡ ä½•å¯¹é½è¾¹ç¼˜ (Geometry-Aligned Edges, GAE) ===
    try:
        # 2.1 ç”¨Cannyæ£€æµ‹é¢œè‰²è¾¹ç¼˜ (CPUæ“ä½œï¼Œå› OpenCVä¸æ”¯æŒGPU)
        color_np = (tile_color.cpu().numpy() * 255).astype('uint8')
        if color_np.shape[0] > 0 and color_np.shape[1] > 0:
            gray = cv2.cvtColor(color_np, cv2.COLOR_RGB2GRAY)
            edges_canny = cv2.Canny(gray, 100, 200)  # æ ‡å‡†Cannyå‚æ•°
            
            # 2.2 ä»…ä¿ç•™ä¸æ·±åº¦ä¸è¿ç»­å¯¹é½çš„è¾¹ç¼˜ (æ ¸å¿ƒåˆ›æ–°!)
            if G_D.numel() > 0:
                tau_D = tau_D_ratio * G_D.max().item()  # æ·±åº¦æ¢¯åº¦é˜ˆå€¼
                G_D_np = G_D.cpu().numpy()
                
                # ç¡®ä¿å°ºå¯¸åŒ¹é…
                if edges_canny.shape == G_D_np.shape:
                    GAE = edges_canny * (G_D_np > tau_D)  # å…³é”®ï¼šè¿‡æ»¤éå‡ ä½•è¾¹ç¼˜
                    GAE_density = GAE.sum() / (edges_canny.shape[0] * edges_canny.shape[1] * 255)  # å½’ä¸€åŒ–åˆ° [0,1]
                else:
                    GAE_density = 0.0
            else:
                GAE_density = 0.0
        else:
            GAE_density = 0.0
    except Exception as e:
        GAE_density = 0.0
    
    # === Step 3: èåˆæŒ‡æ ‡ â†’ GACM ===
    gacm_score = alpha * DD_tile + beta * SC_tile + gamma * GAE_density
    
    # === Step 4: å†³ç­– ===
    decision = (gacm_score > threshold)
    
    return gacm_score, decision

def diagnose_single_image(scene_name, image_idx=0):
    """è¯Šæ–­å•å¼ å›¾ç‰‡çš„tileæ£€æµ‹æ–¹æ³•"""
    print(f"\n{'='*80}")
    print(f"è¯Šæ–­åœºæ™¯: {scene_name}, å›¾ç‰‡: {image_idx}")
    print(f"{'='*80}")
    
    # å›¾ç‰‡è·¯å¾„ - trexåœºæ™¯
    base_path = "/home/ytanaz/access/IBRNet/eval/llff_test"
    gt_path = f"{base_path}/eval_llff_sr/{scene_name}/{image_idx}_gt_rgb_hr.png"
    fine_path = f"{base_path}/eval_llff/{scene_name}/{image_idx}_pred_fine.png"
    sr_path = f"{base_path}/eval_llff_sr/{scene_name}/{image_idx}_pred_sr.png"
    
    # æ¸²æŸ“æ•°æ®è·¯å¾„ - ä½¿ç”¨æ•°å­—ç´¢å¼•
    render_info_path = "/home/ytanaz/access/IBRNet/memory/render_infos"
    weights_path = f"{render_info_path}/render_weights_{image_idx}_n48.pt"
    depth_path = f"{render_info_path}/render_depth_map_{image_idx}_n48.pt"
    
    # æ£€æŸ¥æ–‡ä»¶å­˜åœ¨æ€§
    for path, name in [(gt_path, "GT"), (fine_path, "Fine"), (sr_path, "SR")]:
        if not os.path.exists(path):
            print(f"âŒ ç¼ºå°‘æ–‡ä»¶: {name} - {path}")
            return None
    
    print(f"âœ… æ‰¾åˆ°æ‰€æœ‰å¿…è¦æ–‡ä»¶")
    
    # åŠ è½½å›¾ç‰‡
    gt_img = load_image(gt_path)
    fine_img = load_image(fine_path)
    sr_img = load_image(sr_path)
    
    print(f"å›¾ç‰‡å°ºå¯¸: GT={gt_img.shape}, Fine={fine_img.shape}, SR={sr_img.shape}")
    
    # è®¡ç®—tile-wiseæŸå¤±
    fine_tile_psnr, fine_tile_coords = calculate_tile_wise_psnr(fine_img, gt_img, tile_size=32)
    sr_tile_psnr, sr_tile_coords = calculate_tile_wise_psnr(sr_img, gt_img, tile_size=32)
    
    # è®¡ç®—æ¯ä¸ªtileçš„æŸå¤± (Fine PSNR - SR PSNR)
    tile_loss_info = []
    for fine_info, sr_info in zip(fine_tile_coords, sr_tile_coords):
        loss = fine_info['psnr'] - sr_info['psnr']
        tile_loss_info.append({
            'tile_id': fine_info['tile_id'],
            'coords': fine_info['coords'],
            'fine_psnr': fine_info['psnr'],
            'sr_psnr': sr_info['psnr'],
            'loss': loss
        })
    
    # æŒ‰æŸå¤±æ’åºï¼Œæ‰¾å‡ºæœ€å·®çš„tiles
    tile_loss_info.sort(key=lambda x: x['loss'], reverse=True)
    
    print(f"\nğŸ“Š TileæŸå¤±ç»Ÿè®¡:")
    print(f"å¹³å‡æŸå¤±: {np.mean([t['loss'] for t in tile_loss_info]):.2f} dB")
    print(f"æœ€å¤§æŸå¤±: {tile_loss_info[0]['loss']:.2f} dB")
    print(f"æœ€å°æŸå¤±: {tile_loss_info[-1]['loss']:.2f} dB")
    
    # åˆ†ææœ€å·®çš„20ä¸ªtiles
    worst_tiles = tile_loss_info[:30]
    print(f"\nğŸ” åˆ†ææœ€å·®çš„20ä¸ªtiles:")
    
    # åŠ è½½è¾…åŠ©æ•°æ®
    volume_confidence_map = extract_volume_rendering_confidence(weights_path)
    depth_discontinuity_map = extract_depth_discontinuity_score(depth_path)
    
    # æ£€æµ‹ç»“æœ
    detection_results = []
    
    for i, tile_info in enumerate(worst_tiles):
        tile_id = tile_info['tile_id']
        coords = tile_info['coords']
        loss = tile_info['loss']
        h_start, h_end, w_start, w_end = coords
        
        print(f"\n--- Tile {i+1}: {tile_id} (æŸå¤±: {loss:.2f} dB) ---")
        
        # æå–tileåŒºåŸŸ
        fine_tile = fine_img[h_start:h_end, w_start:w_end, :]
        sr_tile = sr_img[h_start:h_end, w_start:w_end, :]
        gt_tile = gt_img[h_start:h_end, w_start:w_end, :]
        
        result = {
            'tile_id': tile_id,
            'loss': loss,
            'fine_psnr': tile_info['fine_psnr'],
            'sr_psnr': tile_info['sr_psnr']
        }
        
        # 1. Cannyé«˜åˆ†è¾¨ç‡æ–¹æ³•
        canny_high_score = extract_canny_high_res(fine_tile)
        canny_high_decision = canny_high_score > 0.160
        result['canny_high_score'] = canny_high_score
        result['canny_high_decision'] = canny_high_decision
        print(f"Cannyé«˜åˆ†è¾¨ç‡: å¾—åˆ†={canny_high_score:.3f}, å†³ç­–={'æ›¿æ¢' if canny_high_decision else 'ä¸æ›¿æ¢'}")
        
        # 2. Cannyä½åˆ†è¾¨ç‡æ–¹æ³•
        canny_low_score = extract_canny_low_res(sr_tile)
        canny_low_decision = canny_low_score > 0.250
        result['canny_low_score'] = canny_low_score
        result['canny_low_decision'] = canny_low_decision
        print(f"Cannyä½åˆ†è¾¨ç‡: å¾—åˆ†={canny_low_score:.3f}, å†³ç­–={'æ›¿æ¢' if canny_low_decision else 'ä¸æ›¿æ¢'}")
        
        # 3. ä½“æ¸²æŸ“ç½®ä¿¡åº¦æ–¹æ³•
        if volume_confidence_map is not None:
            print(volume_confidence_map.shape)
            confidence_tile = volume_confidence_map[h_start:h_end, w_start:w_end]
            volume_score = np.mean(confidence_tile)
            # æ£€æŸ¥NaNå€¼
            if np.isnan(volume_score):
                volume_score = 0.0
                volume_decision = False
                print(f"ä½“æ¸²æŸ“ç½®ä¿¡åº¦: å¾—åˆ†=NaN(è®¾ä¸º0.0), å†³ç­–=ä¸æ›¿æ¢")
            else:
                volume_decision = volume_score < 0.5  # ç½®ä¿¡åº¦ä½æ—¶éœ€è¦æ›¿æ¢
                print(f"ä½“æ¸²æŸ“ç½®ä¿¡åº¦: å¾—åˆ†={volume_score:.3f}, å†³ç­–={'æ›¿æ¢' if volume_decision else 'ä¸æ›¿æ¢'}")
            result['volume_score'] = volume_score
            result['volume_decision'] = volume_decision
        else:
            result['volume_score'] = None
            result['volume_decision'] = None
            print(f"ä½“æ¸²æŸ“ç½®ä¿¡åº¦: æ•°æ®ç¼ºå¤±")
        
        # 4. æ·±åº¦ä¸è¿ç»­æ€§æ–¹æ³•
        if depth_discontinuity_map is not None:
            depth_tile = depth_discontinuity_map[h_start:h_end, w_start:w_end]
            depth_score = np.mean(depth_tile)
            # æ£€æŸ¥NaNå€¼
            if np.isnan(depth_score):
                depth_score = 0.0
                depth_decision = False
                print(f"æ·±åº¦ä¸è¿ç»­æ€§: å¾—åˆ†=NaN(è®¾ä¸º0.0), å†³ç­–=ä¸æ›¿æ¢")
            else:
                depth_decision = depth_score > 0.1  # æ·±åº¦å˜åŒ–å¤§æ—¶éœ€è¦æ›¿æ¢
                print(f"æ·±åº¦ä¸è¿ç»­æ€§: å¾—åˆ†={depth_score:.3f}, å†³ç­–={'æ›¿æ¢' if depth_decision else 'ä¸æ›¿æ¢'}")
            result['depth_score'] = depth_score
            result['depth_decision'] = depth_decision
        else:
            result['depth_score'] = None
            result['depth_decision'] = None
            print(f"æ·±åº¦ä¸è¿ç»­æ€§: æ•°æ®ç¼ºå¤±")
        
        # 5. GACMæ–¹æ³•
        if depth_discontinuity_map is not None:
            try:
                # å‡†å¤‡GACMè¾“å…¥
                tile_color = torch.from_numpy(sr_tile).float()
                
                # ä»å®Œæ•´æ·±åº¦å›¾ä¸­æå–å¯¹åº”tile
                depth_map = torch.load(depth_path, map_location='cpu')
                tile_depth = depth_map[h_start:h_end, w_start:w_end]
                
                gacm_score, gacm_decision = compute_gacm(tile_color, tile_depth, alpha=0.4, beta=0.3, gamma=0.3, tau_D_ratio=0.1, threshold=0.01)
                result['gacm_score'] = gacm_score
                result['gacm_decision'] = gacm_decision
                print(f"GACMæ–¹æ³•: å¾—åˆ†={gacm_score:.3f}, å†³ç­–={'æ›¿æ¢' if gacm_decision else 'ä¸æ›¿æ¢'}")
            except Exception as e:
                result['gacm_score'] = None
                result['gacm_decision'] = None
                print(f"GACMæ–¹æ³•: è®¡ç®—é”™è¯¯ - {e}")
        else:
            result['gacm_score'] = None
            result['gacm_decision'] = None
            print(f"GACMæ–¹æ³•: æ·±åº¦æ•°æ®ç¼ºå¤±")
        
        detection_results.append(result)
    
    return detection_results, worst_tiles

def analyze_detection_accuracy(detection_results):
    """åˆ†æå„æ–¹æ³•çš„æ£€æµ‹å‡†ç¡®æ€§"""
    print(f"\n{'='*80}")
    print(f"å„æ–¹æ³•æ£€æµ‹å‡†ç¡®æ€§åˆ†æ")
    print(f"{'='*80}")
    
    methods = [
        ('canny_high', 'Cannyé«˜åˆ†è¾¨ç‡'),
        ('canny_low', 'Cannyä½åˆ†è¾¨ç‡'),
        ('volume', 'ä½“æ¸²æŸ“ç½®ä¿¡åº¦'),
        ('depth', 'æ·±åº¦ä¸è¿ç»­æ€§'),
        ('gacm', 'GACMæ–¹æ³•')
    ]
    
    # è¿™é‡Œæˆ‘ä»¬å‡è®¾æŸå¤±æœ€å¤§çš„tilesåº”è¯¥è¢«æ›¿æ¢ï¼ˆå³ground truthæ˜¯éœ€è¦æ›¿æ¢ï¼‰
    # å› ä¸ºè¿™äº›æ˜¯SRè¡¨ç°æœ€å·®çš„tiles
    total_tiles = len(detection_results)
    
    print(f"åˆ†æå¯¹è±¡: æŸå¤±æœ€å¤§çš„{total_tiles}ä¸ªtiles (ç†è®ºä¸Šéƒ½åº”è¯¥è¢«æ›¿æ¢)")
    print(f"\n{'æ–¹æ³•':<15} {'æ£€æµ‹ç‡':<10} {'ç¼ºå¤±ç‡':<10} {'å¯ç”¨æ€§':<10}")
    print("-" * 50)
    
    for method_key, method_name in methods:
        detected_count = 0
        available_count = 0
        
        for result in detection_results:
            decision_key = f"{method_key}_decision"
            if result[decision_key] is not None:
                available_count += 1
                if result[decision_key]:  # å¦‚æœæ–¹æ³•å†³å®šæ›¿æ¢
                    detected_count += 1
        
        if available_count > 0:
            detection_rate = detected_count / available_count
            miss_rate = 1 - detection_rate
            availability = available_count / total_tiles
            
            print(f"{method_name:<15} {detection_rate:<9.1%} {miss_rate:<9.1%} {availability:<9.1%}")
        else:
            print(f"{method_name:<15} {'N/A':<9} {'N/A':<9} {'0.0%':<9}")
    
    # è¯¦ç»†åˆ†ææ¯ä¸ªæ–¹æ³•çš„å¾—åˆ†åˆ†å¸ƒ
    # print(f"\nğŸ“Š å„æ–¹æ³•å¾—åˆ†åˆ†å¸ƒ:")
    
    # for method_key, method_name in methods:
    #     score_key = f"{method_key}_score"
    #     scores = [r[score_key] for r in detection_results if r[score_key] is not None]
        
    #     if scores:
    #         print(f"\n{method_name}:")
    #         print(f"  å¾—åˆ†èŒƒå›´: {min(scores):.3f} - {max(scores):.3f}")
    #         print(f"  å¹³å‡å¾—åˆ†: {np.mean(scores):.3f} Â± {np.std(scores):.3f}")
    #         print(f"  ä¸­ä½æ•°: {np.median(scores):.3f}")
    #     else:
    #         print(f"\n{method_name}: æ— å¯ç”¨æ•°æ®")

def save_detection_report(detection_results, scene_name, image_idx):
    """ä¿å­˜è¯¦ç»†çš„æ£€æµ‹æŠ¥å‘Š"""
    report_path = f"../results/reports/tile_detection_diagnosis_{scene_name}_{image_idx}.txt"
    
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(f"=== Tileæ£€æµ‹æ–¹æ³•è¯Šæ–­æŠ¥å‘Š ===\n")
        f.write(f"åœºæ™¯: {scene_name}\n")
        f.write(f"å›¾ç‰‡: {image_idx}\n")
        f.write(f"åˆ†ææ—¶é—´: {pd.Timestamp.now()}\n\n")
        
        f.write("=== æœ€å·®20ä¸ªTilesè¯¦ç»†æ£€æµ‹ç»“æœ ===\n")
        f.write(f"{'Rank':<4} {'TileID':<8} {'æŸå¤±':<8} {'Cannyé«˜':<8} {'Cannyä½':<8} {'ä½“æ¸²æŸ“':<8} {'æ·±åº¦':<8} {'GACM':<8}\n")
        f.write("-" * 70 + "\n")
        
        for i, result in enumerate(detection_results):
            tile_id = result['tile_id']
            loss = result['loss']
            
            canny_high = "âœ“" if result['canny_high_decision'] else "âœ—" if result['canny_high_decision'] is not None else "N/A"
            canny_low = "âœ“" if result['canny_low_decision'] else "âœ—" if result['canny_low_decision'] is not None else "N/A"
            volume = "âœ“" if result['volume_decision'] else "âœ—" if result['volume_decision'] is not None else "N/A"
            depth = "âœ“" if result['depth_decision'] else "âœ—" if result['depth_decision'] is not None else "N/A"
            gacm = "âœ“" if result['gacm_decision'] else "âœ—" if result['gacm_decision'] is not None else "N/A"
            
            f.write(f"{i+1:<4} {str(tile_id):<8} {loss:<8.2f} {canny_high:<8} {canny_low:<8} {volume:<8} {depth:<8} {gacm:<8}\n")
        
        f.write("\nç¬¦å·è¯´æ˜: âœ“=éœ€è¦æ›¿æ¢, âœ—=ä¸éœ€è¦æ›¿æ¢, N/A=æ•°æ®ä¸å¯ç”¨\n")
    
    print(f"æ£€æµ‹æŠ¥å‘Šä¿å­˜åˆ°: {report_path}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ” Tileæ£€æµ‹æ–¹æ³•è¯Šæ–­å·¥å…·")
    print("="*80)
    
    # æµ‹è¯•åœºæ™¯ - trexçš„å¤šä¸ªå›¾ç‰‡
    test_cases = [
        ("trex", 0),
        ("trex", 1),
        ("trex", 2),
    ]
    
    all_results = []
    
    for scene_name, image_idx in test_cases:
        print(f"\n{'='*20} å¤„ç† {scene_name} å›¾ç‰‡ {image_idx} {'='*20}")
        
        # è¯Šæ–­å•å¼ å›¾ç‰‡
        result = diagnose_single_image(scene_name, image_idx)
        
        if result is not None:
            detection_results, worst_tiles = result
            # åˆ†ææ£€æµ‹å‡†ç¡®æ€§
            analyze_detection_accuracy(detection_results)
            
            # åˆ›å»ºå¯è§†åŒ–
            # create_detection_visualization(detection_results, scene_name, image_idx)
            
            # ä¿å­˜æŠ¥å‘Š
            save_detection_report(detection_results, scene_name, image_idx)
            
            all_results.extend(detection_results)
        else:
            print(f"âŒ è·³è¿‡ {scene_name} å›¾ç‰‡ {image_idx}ï¼ˆæ•°æ®ä¸å®Œæ•´ï¼‰")
    
    # æ€»ä½“åˆ†æ
    if all_results:
        print(f"\n{'='*80}")
        print(f"æ€»ä½“åˆ†æ (å…±{len(all_results)}ä¸ªæœ€å·®tiles)")
        print(f"{'='*80}")
        analyze_detection_accuracy(all_results)
    
    print(f"\nâœ… è¯Šæ–­å®Œæˆï¼")
    print(f"è¯¦ç»†ç»“æœä¿å­˜åœ¨ ../results/reports/ å’Œ ../results/images/ ç›®å½•ä¸‹")

if __name__ == "__main__":
    main()
