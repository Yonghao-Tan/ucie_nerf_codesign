#!/usr/bin/env python3
"""
é›†æˆNeRF-awareè´¨é‡é¢„æµ‹å™¨åˆ°ç°æœ‰æµ‹è¯•æ¡†æ¶
æ‰©å±•batch_llff_test.pyä»¥æ”¯æŒæ–°çš„åˆ›æ–°æ–¹æ³•
"""
import os
import sys
import numpy as np
import cv2
from PIL import Image
import matplotlib.pyplot as plt
from skimage.metrics import peak_signal_noise_ratio as psnr
import pandas as pd
from pathlib import Path
import time
from tqdm import tqdm
import torch

# å¯¼å…¥æˆ‘ä»¬çš„æ–°é¢„æµ‹å™¨
from nerf_hybrid_predictor import NeRFAwareTileReplacementSystem, TileRenderingData
from manual_canny import manual_canny

class EnhancedTileReplacementTester:
    """å¢å¼ºçš„Tileæ›¿æ¢æµ‹è¯•å™¨ - é›†æˆå¤šç§åˆ›æ–°æ–¹æ³•"""

    def __init__(self, llff_test_root="/home/ytanaz/access/IBRNet/eval/llff_test"):
        self.llff_test_root = Path(llff_test_root)
        self.eval_llff_path = self.llff_test_root / "eval_llff_golden"
        self.eval_llff_sr_path = self.llff_test_root / "eval_llff_sr"
        self.tile_size = 32
        self.fine_tile_size = 16
        
        # åˆ›å»ºä¸åŒçš„é¢„æµ‹å™¨
        self.nerf_system = NeRFAwareTileReplacementSystem(self.tile_size)
        
        # æ–¹æ³•é…ç½®
        self.methods = {
            'canny_highres': {
                'name': 'Cannyé«˜åˆ†è¾¨ç‡',
                'threshold': 0.160,
                'function': self.extract_edge_score_canny
            },
            'canny_lowres': {
                'name': 'Cannyä½åˆ†è¾¨ç‡',
                'threshold': 0.250,
                'function': self.extract_edge_score_canny_lowres
            },
            'nerf_informed': {
                'name': 'NeRFæ„ŸçŸ¥æ–¹æ³•',
                'threshold': 0.5,  # å°†åŠ¨æ€è°ƒæ•´
                'function': self.extract_nerf_informed_score
            },
            'hybrid_adaptive': {
                'name': 'æ··åˆè‡ªé€‚åº”æ–¹æ³•',
                'threshold': 0.5,  # å°†åŠ¨æ€è°ƒæ•´
                'function': self.extract_hybrid_adaptive_score
            }
        }
        
        print(f"ğŸš€ å¢å¼ºæµ‹è¯•å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"æ”¯æŒæ–¹æ³•: {list(self.methods.keys())}")
    
    def get_scenes(self):
        """è·å–æ‰€æœ‰æµ‹è¯•åœºæ™¯"""
        scenes = []
        if self.eval_llff_path.exists():
            for scene_dir in self.eval_llff_path.iterdir():
                if scene_dir.is_dir() and not scene_dir.name.startswith('.'):
                    scenes.append(scene_dir.name)
        return sorted(scenes)
    
    def get_image_indices(self, scene_path):
        """è·å–åœºæ™¯ä¸­æ‰€æœ‰å›¾åƒçš„ç´¢å¼•"""
        indices = []
        for file_path in scene_path.glob("*_gt_rgb.png"):
            index = int(file_path.stem.split('_')[0])
            indices.append(index)
        return sorted(indices)
    
    def extract_edge_score_canny(self, tile):
        """æ ‡å‡†Cannyè¾¹ç¼˜æ£€æµ‹"""
        if tile.max() > 1.0:
            tile = tile.astype(np.float32) / 255.0
            
        gray = cv2.cvtColor((tile * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)
        edges = cv2.Canny(gray, 50, 150)
        return float(np.sum(edges > 0) / edges.size)
    
    def extract_edge_score_canny_lowres(self, tile):
        """ä½åˆ†è¾¨ç‡Cannyè¾¹ç¼˜æ£€æµ‹"""
        # æ¨¡æ‹Ÿä½åˆ†è¾¨ç‡åˆ†æè¿‡ç¨‹
        h, w = tile.shape[:2]
        
        # ä¸‹é‡‡æ ·åˆ°fineåˆ†è¾¨ç‡
        fine_tile = cv2.resize(tile, (self.fine_tile_size, self.fine_tile_size))
        
        # åœ¨ä½åˆ†è¾¨ç‡ä¸Šåšè¾¹ç¼˜æ£€æµ‹
        if fine_tile.max() > 1.0:
            fine_tile = fine_tile.astype(np.float32) / 255.0
        
        gray = cv2.cvtColor((fine_tile * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)
        edges = cv2.Canny(gray, 50, 150)
        
        return float(np.sum(edges > 0) / edges.size)
    
    def extract_nerf_informed_score(self, tile_rgb, render_data=None):
        """NeRFæ„ŸçŸ¥å¾—åˆ†æå–"""
        if render_data is None:
            # å¦‚æœæ²¡æœ‰çœŸå®çš„NeRFæ•°æ®ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®è¿›è¡Œæ¼”ç¤º
            render_data = self._simulate_render_data(tile_rgb.shape[:2])
        
        # æ„å»ºtileæ•°æ®
        tile_data = TileRenderingData(
            rgb=tile_rgb,
            depth=render_data.get('depth'),
            weights=render_data.get('weights'),
            alpha=render_data.get('alpha'),
            mask=render_data.get('mask')
        )
        
        # ä½¿ç”¨NeRFé¢„æµ‹å™¨è®¡ç®—å¾—åˆ†
        scores = self.nerf_system.predictor.compute_tile_scores(tile_data)
        return scores['final_score']
    
    def extract_hybrid_adaptive_score(self, tile_rgb, render_data=None, global_stats=None):
        """æ··åˆè‡ªé€‚åº”å¾—åˆ†æå–"""
        if render_data is None:
            render_data = self._simulate_render_data(tile_rgb.shape[:2])
        
        # 1. NeRFç‰¹å¾
        nerf_score = self.extract_nerf_informed_score(tile_rgb, render_data)
        
        # 2. ä¼ ç»Ÿç‰¹å¾
        canny_score = self.extract_edge_score_canny(tile_rgb)
        
        # 3. çº¹ç†å¤æ‚åº¦
        gray = cv2.cvtColor((tile_rgb * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)
        texture_score = np.std(gray) / 255.0
        
        # 4. é«˜é¢‘å†…å®¹
        laplacian = cv2.Laplacian(gray, cv2.CV_64F)
        high_freq_score = np.var(laplacian) / (255.0**2)
        
        # åŠ æƒç»„åˆ
        hybrid_score = (
            0.4 * nerf_score +
            0.3 * canny_score +
            0.2 * texture_score +
            0.1 * high_freq_score
        )
        
        return float(hybrid_score)
    
    def _simulate_render_data(self, tile_shape):
        """æ¨¡æ‹ŸNeRFæ¸²æŸ“æ•°æ®ï¼ˆç”¨äºæ¼”ç¤ºï¼‰"""
        h, w = tile_shape
        n_samples = 64
        
        # æ¨¡æ‹Ÿæ·±åº¦å›¾ - æ·»åŠ ä¸€äº›å‡ ä½•å¤æ‚åº¦
        x, y = np.meshgrid(np.linspace(0, 1, w), np.linspace(0, 1, h))
        depth = 2.0 + 0.5 * np.sin(4 * np.pi * x) * np.cos(4 * np.pi * y)
        depth += 0.1 * np.random.randn(h, w)  # æ·»åŠ å™ªå£°
        
        # æ¨¡æ‹Ÿæƒé‡ - åŸºäºæ·±åº¦å˜åŒ–
        weights = np.random.exponential(1.0, (h, w, n_samples))
        
        # è®©æƒé‡åœ¨æ·±åº¦å˜åŒ–å¤§çš„åœ°æ–¹æ›´åˆ†æ•£ï¼ˆä¸ç¡®å®šæ€§æ›´é«˜ï¼‰
        depth_grad = np.gradient(depth)
        complexity = np.sqrt(depth_grad[0]**2 + depth_grad[1]**2)
        
        for i in range(n_samples):
            weights[:, :, i] *= (1.0 + 2.0 * complexity)  # å¤æ‚åŒºåŸŸæƒé‡æ›´åˆ†æ•£
        
        # å½’ä¸€åŒ–æƒé‡
        weights = weights / (weights.sum(axis=-1, keepdims=True) + 1e-8)
        
        # æ¨¡æ‹Ÿalphaå€¼
        alpha = np.random.exponential(0.5, (h, w, n_samples))
        
        # æ¨¡æ‹Ÿmask - å¤§éƒ¨åˆ†åŒºåŸŸå¯è§
        mask = (np.random.rand(h, w) > 0.1).astype(float)
        
        return {
            'depth': depth,
            'weights': weights,
            'alpha': alpha,
            'mask': mask
        }
    
    def apply_tile_replacement_method(self, sr_img, org_img, method_name, render_data=None):
        """åº”ç”¨æŒ‡å®šçš„tileæ›¿æ¢æ–¹æ³•"""
        h, w = sr_img.shape[:2]
        tile_h, tile_w = h // self.tile_size, w // self.tile_size
        
        hybrid_img = sr_img.copy()
        replaced_tiles = 0
        all_scores = []
        
        # è·å–æ–¹æ³•é…ç½®
        method_config = self.methods[method_name]
        threshold = method_config['threshold']
        extract_func = method_config['function']
        
        # å¦‚æœæ˜¯NeRFæ–¹æ³•ï¼Œåˆ†æå…¨å±€ç»Ÿè®¡ä¿¡æ¯
        global_stats = None
        if 'nerf' in method_name or 'hybrid' in method_name:
            if render_data is None:
                render_data = self._simulate_render_data((h, w))
            global_stats = self._analyze_global_scene(render_data)
            
            # åŠ¨æ€è°ƒæ•´é˜ˆå€¼
            if 'adaptive' in method_name:
                threshold = self._get_adaptive_threshold(global_stats)
        
        # é€tileå¤„ç†
        for i in range(tile_h):
            for j in range(tile_w):
                y_start, y_end = i * self.tile_size, (i + 1) * self.tile_size
                x_start, x_end = j * self.tile_size, (j + 1) * self.tile_size
                
                sr_tile = sr_img[y_start:y_end, x_start:x_end]
                
                # æå–tileçº§åˆ«çš„æ¸²æŸ“æ•°æ®
                tile_render_data = None
                if render_data is not None:
                    tile_render_data = {}
                    for key, value in render_data.items():
                        if value is not None:
                            if len(value.shape) == 2:
                                tile_render_data[key] = value[y_start:y_end, x_start:x_end]
                            elif len(value.shape) == 3:
                                tile_render_data[key] = value[y_start:y_end, x_start:x_end, :]
                
                # è®¡ç®—å¾—åˆ†
                if method_name in ['nerf_informed', 'hybrid_adaptive']:
                    score = extract_func(sr_tile, tile_render_data, global_stats)
                else:
                    score = extract_func(sr_tile)
                
                all_scores.append(score)
                
                # æ›¿æ¢å†³ç­–
                if score > threshold:
                    hybrid_img[y_start:y_end, x_start:x_end] = org_img[y_start:y_end, x_start:x_end]
                    replaced_tiles += 1
        
        replacement_ratio = replaced_tiles / (tile_h * tile_w)
        
        return {
            'hybrid_img': hybrid_img,
            'replaced_tiles': replaced_tiles,
            'total_tiles': tile_h * tile_w,
            'replacement_ratio': replacement_ratio,
            'all_scores': all_scores,
            'threshold_used': threshold
        }
    
    def _analyze_global_scene(self, render_data):
        """åˆ†æå…¨å±€åœºæ™¯ç»Ÿè®¡ä¿¡æ¯"""
        stats = {}
        
        if 'depth' in render_data:
            depth = render_data['depth']
            stats['depth_range'] = np.ptp(depth)
            stats['depth_std'] = np.std(depth)
            stats['mean_depth'] = np.mean(depth)
        
        if 'weights' in render_data:
            weights = render_data['weights']
            weights_norm = weights / (weights.sum(axis=-1, keepdims=True) + 1e-8)
            entropy = -np.sum(weights_norm * np.log(weights_norm + 1e-8), axis=-1)
            stats['global_uncertainty'] = np.mean(entropy)
        
        # è®¡ç®—å¤æ‚åº¦
        complexity_factors = []
        if 'depth_range' in stats and stats['mean_depth'] > 0:
            complexity_factors.append(stats['depth_range'] / stats['mean_depth'])
        if 'global_uncertainty' in stats:
            complexity_factors.append(stats['global_uncertainty'])
        
        stats['complexity'] = np.mean(complexity_factors) if complexity_factors else 0.5
        
        return stats
    
    def _get_adaptive_threshold(self, global_stats):
        """è·å–è‡ªé€‚åº”é˜ˆå€¼"""
        base_threshold = 0.5
        complexity = global_stats.get('complexity', 0.5)
        
        # å¤æ‚åœºæ™¯ä½¿ç”¨æ›´ä½é˜ˆå€¼
        adaptive_threshold = base_threshold - 0.2 * complexity
        return np.clip(adaptive_threshold, 0.3, 0.7)
    
    def test_single_image_all_methods(self, scene_name, image_index, save_results=True):
        """æµ‹è¯•å•å¼ å›¾åƒçš„æ‰€æœ‰æ–¹æ³•"""
        # åŠ è½½å›¾åƒ
        scene_path_golden = self.eval_llff_path / scene_name
        scene_path_sr = self.eval_llff_sr_path / scene_name
        
        gt_path = scene_path_golden / f"{image_index:03d}_gt_rgb.png"
        sr_path = scene_path_sr / f"{image_index:03d}_pred_fine.png"
        
        if not gt_path.exists() or not sr_path.exists():
            return None
        
        # è¯»å–å›¾åƒ
        gt_img = np.array(Image.open(gt_path)).astype(np.float32) / 255.0
        sr_img = np.array(Image.open(sr_path)).astype(np.float32) / 255.0
        
        # ç¡®ä¿å°ºå¯¸åŒ¹é…
        if gt_img.shape != sr_img.shape:
            sr_img = cv2.resize(sr_img, (gt_img.shape[1], gt_img.shape[0]))
        
        # ç”Ÿæˆæ¸²æŸ“æ•°æ®ï¼ˆå®é™…ä½¿ç”¨æ—¶åº”è¯¥ä»NeRFæ¸²æŸ“å™¨è·å–ï¼‰
        render_data = self._simulate_render_data(gt_img.shape[:2])
        
        results = {}
        
        # æµ‹è¯•æ‰€æœ‰æ–¹æ³•
        for method_name in self.methods.keys():
            print(f"  æµ‹è¯•æ–¹æ³•: {self.methods[method_name]['name']}")
            
            method_result = self.apply_tile_replacement_method(
                sr_img, gt_img, method_name, render_data
            )
            
            # è®¡ç®—PSNR
            hybrid_psnr = psnr(gt_img, method_result['hybrid_img'])
            sr_psnr = psnr(gt_img, sr_img)
            improvement = hybrid_psnr - sr_psnr
            
            results[method_name] = {
                'hybrid_psnr': hybrid_psnr,
                'sr_psnr': sr_psnr,
                'improvement': improvement,
                'replacement_ratio': method_result['replacement_ratio'],
                'replaced_tiles': method_result['replaced_tiles'],
                'threshold_used': method_result['threshold_used'],
                'hybrid_img': method_result['hybrid_img']
            }
            
            print(f"    PSNRæå‡: {improvement:.3f}dB, æ›¿æ¢ç‡: {method_result['replacement_ratio']:.1%}")
        
        # ä¿å­˜ç»“æœ
        if save_results:
            self._save_comparison_results(scene_name, image_index, results, gt_img, sr_img)
        
        return results
    
    def _save_comparison_results(self, scene_name, image_index, results, gt_img, sr_img):
        """ä¿å­˜å¯¹æ¯”ç»“æœ"""
        output_dir = Path(f"enhanced_test_results/{scene_name}")
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # åˆ›å»ºå¯¹æ¯”å›¾
        fig, axes = plt.subplots(2, 3, figsize=(15, 10))
        
        # åŸå§‹å›¾åƒ
        axes[0, 0].imshow(gt_img)
        axes[0, 0].set_title('Ground Truth')
        axes[0, 0].axis('off')
        
        axes[0, 1].imshow(sr_img)
        axes[0, 1].set_title(f'SR (PSNR: {results["canny_highres"]["sr_psnr"]:.2f}dB)')
        axes[0, 1].axis('off')
        
        # æ˜¾ç¤ºæœ€å¥½çš„æ–¹æ³•
        best_method = max(results.keys(), key=lambda k: results[k]['improvement'])
        best_result = results[best_method]
        
        axes[0, 2].imshow(best_result['hybrid_img'])
        axes[0, 2].set_title(f'Best: {self.methods[best_method]["name"]}\n'
                            f'PSNR: {best_result["hybrid_psnr"]:.2f}dB '
                            f'(+{best_result["improvement"]:.2f})')
        axes[0, 2].axis('off')
        
        # æ˜¾ç¤ºå…¶ä»–æ–¹æ³•
        method_names = list(results.keys())
        for i, method_name in enumerate(method_names[:3]):
            if i < 3:
                result = results[method_name]
                axes[1, i].imshow(result['hybrid_img'])
                axes[1, i].set_title(f'{self.methods[method_name]["name"]}\n'
                                   f'+{result["improvement"]:.2f}dB, '
                                   f'{result["replacement_ratio"]:.1%} replaced')
                axes[1, i].axis('off')
        
        plt.tight_layout()
        plt.savefig(output_dir / f"{image_index:03d}_comparison.png", dpi=150, bbox_inches='tight')
        plt.close()
        
        # ä¿å­˜æ•°å€¼ç»“æœ
        summary = {
            'scene': scene_name,
            'image_index': image_index,
            'gt_psnr_baseline': results[list(results.keys())[0]]['sr_psnr']
        }
        
        for method_name, result in results.items():
            prefix = method_name
            summary[f'{prefix}_psnr'] = result['hybrid_psnr']
            summary[f'{prefix}_improvement'] = result['improvement']
            summary[f'{prefix}_replacement_ratio'] = result['replacement_ratio']
            summary[f'{prefix}_threshold'] = result['threshold_used']
        
        # ä¿å­˜åˆ°CSV
        csv_path = output_dir / "results_summary.csv"
        df = pd.DataFrame([summary])
        
        if csv_path.exists():
            existing_df = pd.read_csv(csv_path)
            df = pd.concat([existing_df, df], ignore_index=True)
        
        df.to_csv(csv_path, index=False)
    
    def test_all_scenes(self, max_images_per_scene=5):
        """æµ‹è¯•æ‰€æœ‰åœºæ™¯"""
        scenes = self.get_scenes()
        all_results = []
        
        print(f"ğŸ§ª å¼€å§‹æµ‹è¯•ï¼Œå…±{len(scenes)}ä¸ªåœºæ™¯")
        
        for scene_name in scenes:
            print(f"\nğŸ“ æµ‹è¯•åœºæ™¯: {scene_name}")
            
            scene_path = self.eval_llff_path / scene_name
            image_indices = self.get_image_indices(scene_path)
            
            # é™åˆ¶æ¯ä¸ªåœºæ™¯çš„å›¾åƒæ•°é‡
            test_indices = image_indices[:max_images_per_scene]
            
            for image_index in test_indices:
                print(f"  ğŸ–¼ï¸  æµ‹è¯•å›¾åƒ: {image_index:03d}")
                
                results = self.test_single_image_all_methods(scene_name, image_index)
                
                if results:
                    # æ·»åŠ åœºæ™¯å’Œå›¾åƒä¿¡æ¯
                    for method_name, result in results.items():
                        result['scene'] = scene_name
                        result['image_index'] = image_index
                        result['method'] = method_name
                    
                    all_results.extend(results.values())
        
        # ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
        self._generate_summary_report(all_results)
        
        return all_results
    
    def _generate_summary_report(self, all_results):
        """ç”Ÿæˆæ€»ç»“æŠ¥å‘Š"""
        if not all_results:
            return
        
        df = pd.DataFrame(all_results)
        
        # æŒ‰æ–¹æ³•åˆ†ç»„ç»Ÿè®¡
        method_stats = df.groupby('method').agg({
            'improvement': ['mean', 'std', 'count'],
            'replacement_ratio': ['mean', 'std'],
            'hybrid_psnr': 'mean'
        }).round(4)
        
        print(f"\nğŸ“Š æµ‹è¯•æ€»ç»“æŠ¥å‘Š")
        print("=" * 60)
        print(method_stats)
        
        # ä¿å­˜è¯¦ç»†ç»“æœ
        output_dir = Path("enhanced_test_results")
        output_dir.mkdir(exist_ok=True)
        
        df.to_csv(output_dir / "complete_results.csv", index=False)
        method_stats.to_csv(output_dir / "method_summary.csv")
        
        # åˆ›å»ºå¯¹æ¯”å›¾è¡¨
        self._create_summary_plots(df, output_dir)
        
        print(f"\nâœ… ç»“æœå·²ä¿å­˜åˆ°: {output_dir}")
    
    def _create_summary_plots(self, df, output_dir):
        """åˆ›å»ºæ€»ç»“å›¾è¡¨"""
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        
        # 1. PSNRæ”¹è¿›å¯¹æ¯”
        method_improvements = df.groupby('method')['improvement'].mean()
        axes[0, 0].bar(range(len(method_improvements)), method_improvements.values)
        axes[0, 0].set_xticks(range(len(method_improvements)))
        axes[0, 0].set_xticklabels([self.methods[m]['name'] for m in method_improvements.index], 
                                  rotation=45, ha='right')
        axes[0, 0].set_ylabel('Average PSNR Improvement (dB)')
        axes[0, 0].set_title('PSNR Improvement by Method')
        axes[0, 0].grid(True, alpha=0.3)
        
        # 2. æ›¿æ¢ç‡å¯¹æ¯”
        method_ratios = df.groupby('method')['replacement_ratio'].mean()
        axes[0, 1].bar(range(len(method_ratios)), method_ratios.values)
        axes[0, 1].set_xticks(range(len(method_ratios)))
        axes[0, 1].set_xticklabels([self.methods[m]['name'] for m in method_ratios.index], 
                                  rotation=45, ha='right')
        axes[0, 1].set_ylabel('Average Replacement Ratio')
        axes[0, 1].set_title('Tile Replacement Ratio by Method')
        axes[0, 1].grid(True, alpha=0.3)
        
        # 3. æ”¹è¿›åˆ†å¸ƒ
        for method in df['method'].unique():
            method_data = df[df['method'] == method]['improvement']
            axes[1, 0].hist(method_data, alpha=0.7, 
                           label=self.methods[method]['name'], bins=20)
        axes[1, 0].set_xlabel('PSNR Improvement (dB)')
        axes[1, 0].set_ylabel('Frequency')
        axes[1, 0].set_title('Distribution of PSNR Improvements')
        axes[1, 0].legend()
        axes[1, 0].grid(True, alpha=0.3)
        
        # 4. æ•ˆæœ vs æ›¿æ¢ç‡æ•£ç‚¹å›¾
        for method in df['method'].unique():
            method_data = df[df['method'] == method]
            axes[1, 1].scatter(method_data['replacement_ratio'], 
                             method_data['improvement'],
                             alpha=0.6, label=self.methods[method]['name'])
        axes[1, 1].set_xlabel('Replacement Ratio')
        axes[1, 1].set_ylabel('PSNR Improvement (dB)')
        axes[1, 1].set_title('Quality vs Replacement Efficiency')
        axes[1, 1].legend()
        axes[1, 1].grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(output_dir / "summary_analysis.png", dpi=150, bbox_inches='tight')
        plt.close()

def main():
    """ä¸»å‡½æ•° - è¿è¡Œå¢å¼ºæµ‹è¯•"""
    print("ğŸš€ å¯åŠ¨å¢å¼ºçš„NeRF-SR Tileæ›¿æ¢æµ‹è¯•")
    
    # åˆ›å»ºæµ‹è¯•å™¨
    tester = EnhancedTileReplacementTester()
    
    # æµ‹è¯•å•ä¸ªå›¾åƒï¼ˆå¿«é€ŸéªŒè¯ï¼‰
    scenes = tester.get_scenes()
    if scenes:
        print(f"\nğŸ”¬ å¿«é€Ÿæµ‹è¯•ç¬¬ä¸€ä¸ªåœºæ™¯çš„ç¬¬ä¸€å¼ å›¾åƒ...")
        first_scene = scenes[0]
        scene_path = tester.eval_llff_path / first_scene
        indices = tester.get_image_indices(scene_path)
        
        if indices:
            results = tester.test_single_image_all_methods(first_scene, indices[0])
            if results:
                print(f"\nâœ… å¿«é€Ÿæµ‹è¯•å®Œæˆï¼")
                print("å„æ–¹æ³•PSNRæ”¹è¿›:")
                for method, result in results.items():
                    print(f"  {tester.methods[method]['name']}: "
                          f"+{result['improvement']:.3f}dB "
                          f"(æ›¿æ¢ç‡: {result['replacement_ratio']:.1%})")
        
        # è¯¢é—®æ˜¯å¦ç»§ç»­å®Œæ•´æµ‹è¯•
        response = input(f"\næ˜¯å¦ç»§ç»­å®Œæ•´æµ‹è¯•æ‰€æœ‰åœºæ™¯? [y/N]: ").strip().lower()
        if response == 'y':
            print(f"\nğŸ§ª å¼€å§‹å®Œæ•´æµ‹è¯•...")
            all_results = tester.test_all_scenes(max_images_per_scene=3)
            print(f"\nğŸ‰ å®Œæ•´æµ‹è¯•å®Œæˆï¼å…±å¤„ç†{len(all_results)}ä¸ªç»“æœ")
    else:
        print("âŒ æœªæ‰¾åˆ°æµ‹è¯•åœºæ™¯ï¼Œè¯·æ£€æŸ¥è·¯å¾„è®¾ç½®")

if __name__ == "__main__":
    main()
