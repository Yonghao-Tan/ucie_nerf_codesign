#!/usr/bin/env python3
"""
è½»é‡çº§ç¥ç»ç½‘ç»œtileå¤æ‚åº¦é¢„æµ‹å™¨æ€§èƒ½æµ‹è¯•
å¯¹æ¯”ä¸åŒé¢„è®­ç»ƒç½‘ç»œçš„è®¡ç®—å¼€é”€å’Œé¢„æµ‹æ•ˆæœ
"""

import torch
import torch.nn as nn
import torchvision.models as models
import time
import numpy as np
import cv2
from PIL import Image
import matplotlib.pyplot as plt

class CannyPredictor:
    """åŸºçº¿Cannyæ–¹æ³•"""
    def __init__(self, threshold=0.15):
        self.threshold = threshold
    
    def predict_complexity(self, tile):
        gray = cv2.cvtColor(tile, cv2.COLOR_RGB2GRAY)
        edges = cv2.Canny(gray, 50, 150)
        edge_ratio = np.sum(edges > 0) / edges.size
        return edge_ratio > self.threshold

class MobileNetV2Predictor:
    """MobileNetV2è½»é‡çº§é¢„æµ‹å™¨"""
    def __init__(self):
        self.backbone = models.mobilenet_v2(pretrained=True)
        self.feature_extractor = nn.Sequential(
            *list(self.backbone.features.children())[:4]  # å‰4å±‚
        )
        self.feature_extractor.eval()
        
        # å†»ç»“æƒé‡
        for param in self.feature_extractor.parameters():
            param.requires_grad = False
    
    def predict_complexity(self, tile):
        """åŸºäºé¢„è®­ç»ƒç‰¹å¾çš„å¤æ‚åº¦é¢„æµ‹"""
        # é¢„å¤„ç†
        x = torch.from_numpy(tile).permute(2, 0, 1).float() / 255.0
        x = x.unsqueeze(0)  # [1, 3, 16, 16]
        
        # æ ‡å‡†åŒ–ï¼ˆImageNetå‡å€¼å’Œæ ‡å‡†å·®ï¼‰
        normalize = torch.nn.functional.normalize
        
        with torch.no_grad():
            features = self.feature_extractor(x)  # [1, 32, 8, 8]
            
            # å¤æ‚åº¦æŒ‡æ ‡ï¼šç‰¹å¾æ¿€æ´»çš„æ–¹å·®å’Œèƒ½é‡
            feature_var = torch.var(features)
            feature_energy = torch.norm(features)
            
            complexity_score = 0.6 * feature_var + 0.4 * feature_energy
            return complexity_score > 1.5  # å¯è°ƒé˜ˆå€¼

class ResNet18TinyPredictor:
    """ResNet18æç®€ç‰ˆæœ¬"""
    def __init__(self):
        resnet = models.resnet18(pretrained=True)
        self.feature_extractor = nn.Sequential(
            resnet.conv1,
            resnet.bn1, 
            resnet.relu
        )
        self.feature_extractor.eval()
        
        for param in self.feature_extractor.parameters():
            param.requires_grad = False
    
    def predict_complexity(self, tile):
        x = torch.from_numpy(tile).permute(2, 0, 1).float() / 255.0
        x = x.unsqueeze(0)
        
        with torch.no_grad():
            features = self.feature_extractor(x)  # [1, 64, 8, 8]
            
            # æ›´ç²¾ç»†çš„å¤æ‚åº¦åˆ†æ
            spatial_variance = torch.var(features, dim=[2,3]).mean()
            channel_diversity = torch.std(torch.mean(features, dim=[2,3]))
            edge_response = torch.norm(features, dim=1).mean()
            
            complexity_score = (0.4 * spatial_variance + 
                              0.3 * channel_diversity + 
                              0.3 * edge_response)
            return complexity_score > 2.0

class EfficientNetTinyPredictor:
    """EfficientNet-B0è½»é‡ç‰ˆ"""
    def __init__(self):
        try:
            import efficientnet_pytorch
            self.backbone = efficientnet_pytorch.EfficientNet.from_pretrained('efficientnet-b0')
            # åªä½¿ç”¨å‰2ä¸ªMBConv blocks
            self.feature_extractor = nn.Sequential(
                self.backbone._conv_stem,
                self.backbone._bn0,
                self.backbone._swish,
                *list(self.backbone._blocks[:2])
            )
        except ImportError:
            print("EfficientNet not available, using MobileNet as fallback")
            self.feature_extractor = MobileNetV2Predictor().feature_extractor
        
        self.feature_extractor.eval()
        for param in self.feature_extractor.parameters():
            param.requires_grad = False
    
    def predict_complexity(self, tile):
        x = torch.from_numpy(tile).permute(2, 0, 1).float() / 255.0
        x = x.unsqueeze(0)
        
        with torch.no_grad():
            features = self.feature_extractor(x)
            complexity_score = torch.var(features) + 0.5 * torch.mean(torch.abs(features))
            return complexity_score > 0.8

class NeuralPredictorBenchmark:
    """ç¥ç»ç½‘ç»œé¢„æµ‹å™¨æ€§èƒ½æµ‹è¯•"""
    
    def __init__(self):
        self.predictors = {
            'Canny': CannyPredictor(),
            'MobileNetV2': MobileNetV2Predictor(),
            'ResNet18-Tiny': ResNet18TinyPredictor(),
            # 'EfficientNet-Tiny': EfficientNetTinyPredictor()
        }
        
        # ç”Ÿæˆæµ‹è¯•æ•°æ®
        self.test_tiles = self.generate_test_tiles()
        
    def generate_test_tiles(self, num_tiles=100):
        """ç”Ÿæˆå¤šæ ·åŒ–çš„æµ‹è¯•tiles"""
        tiles = []
        
        # ç®€å•çº¹ç†
        for _ in range(30):
            tile = np.random.randint(0, 255, (16, 16, 3), dtype=np.uint8)
            tiles.append(tile)
        
        # è¾¹ç¼˜ä¸°å¯Œ
        for _ in range(30):
            tile = np.zeros((16, 16, 3), dtype=np.uint8)
            cv2.rectangle(tile, (4, 4), (12, 12), (255, 255, 255), 1)
            cv2.line(tile, (0, 8), (16, 8), (128, 128, 128), 1)
            tiles.append(tile)
        
        # å¤æ‚çº¹ç†
        for _ in range(40):
            tile = np.random.randint(0, 255, (16, 16, 3), dtype=np.uint8)
            # æ·»åŠ ç½‘æ ¼
            for i in range(0, 16, 4):
                cv2.line(tile, (i, 0), (i, 16), (0, 0, 0), 1)
                cv2.line(tile, (0, i), (16, i), (0, 0, 0), 1)
            tiles.append(tile)
        
        return tiles
    
    def benchmark_speed(self, num_iterations=1000):
        """æµ‹è¯•æ¨ç†é€Ÿåº¦"""
        results = {}
        
        print("ğŸš€ å¼€å§‹é€Ÿåº¦æµ‹è¯•...")
        print(f"æµ‹è¯•æ•°æ®: {len(self.test_tiles)} tiles Ã— {num_iterations} iterations")
        
        for name, predictor in self.predictors.items():
            print(f"\næµ‹è¯• {name}...")
            
            # é¢„çƒ­
            for tile in self.test_tiles[:10]:
                _ = predictor.predict_complexity(tile)
            
            # æ­£å¼æµ‹è¯•
            start_time = time.time()
            for _ in range(num_iterations):
                for tile in self.test_tiles:
                    _ = predictor.predict_complexity(tile)
            end_time = time.time()
            
            total_predictions = len(self.test_tiles) * num_iterations
            avg_time_per_tile = (end_time - start_time) / total_predictions * 1000  # ms
            
            results[name] = {
                'total_time': end_time - start_time,
                'avg_time_per_tile_ms': avg_time_per_tile,
                'throughput_tiles_per_sec': total_predictions / (end_time - start_time)
            }
            
            print(f"  æ€»æ—¶é—´: {results[name]['total_time']:.3f}s")
            print(f"  å¹³å‡æ¯tile: {avg_time_per_tile:.4f}ms")
            print(f"  ååé‡: {results[name]['throughput_tiles_per_sec']:.1f} tiles/s")
        
        return results
    
    def benchmark_accuracy(self):
        """æµ‹è¯•é¢„æµ‹å‡†ç¡®æ€§ï¼ˆä¸Cannyå¯¹æ¯”ï¼‰"""
        print("\nğŸ¯ å¼€å§‹å‡†ç¡®æ€§æµ‹è¯•...")
        
        canny_predictions = []
        neural_predictions = {name: [] for name in self.predictors.keys() if name != 'Canny'}
        
        # è·å–æ‰€æœ‰é¢„æµ‹ç»“æœ
        for tile in self.test_tiles:
            canny_pred = self.predictors['Canny'].predict_complexity(tile)
            canny_predictions.append(canny_pred)
            
            for name, predictor in self.predictors.items():
                if name != 'Canny':
                    pred = predictor.predict_complexity(tile)
                    neural_predictions[name].append(pred)
        
        # è®¡ç®—ä¸Cannyçš„ä¸€è‡´æ€§
        results = {}
        for name, predictions in neural_predictions.items():
            agreement = np.mean(np.array(predictions) == np.array(canny_predictions))
            results[name] = {
                'agreement_with_canny': agreement,
                'positive_rate': np.mean(predictions),
                'canny_positive_rate': np.mean(canny_predictions)
            }
            
            print(f"\n{name}:")
            print(f"  ä¸Cannyä¸€è‡´æ€§: {agreement:.3f}")
            print(f"  é˜³æ€§ç‡: {np.mean(predictions):.3f}")
            print(f"  Cannyé˜³æ€§ç‡: {np.mean(canny_predictions):.3f}")
        
        return results
    
    def analyze_computational_overhead(self):
        """åˆ†æè®¡ç®—å¼€é”€å¯¹IBRNetçš„å½±å“"""
        print("\nğŸ“Š è®¡ç®—å¼€é”€åˆ†æ...")
        
        # IBRNetåŸºå‡†æ•°æ®ï¼ˆæ ¹æ®æ‚¨çš„é¡¹ç›®æ•°æ®ï¼‰
        ibrnet_time_per_image = 30  # ç§’ï¼Œ1000Ã—800å›¾åƒ
        tiles_per_image = (1000 // 16) * (800 // 16)  # çº¦3125ä¸ªtiles
        
        speed_results = self.benchmark_speed(100)  # å°è§„æ¨¡æµ‹è¯•
        
        overhead_analysis = {}
        for name, stats in speed_results.items():
            time_per_tile_s = stats['avg_time_per_tile_ms'] / 1000
            total_overhead_per_image = time_per_tile_s * tiles_per_image
            overhead_percentage = (total_overhead_per_image / ibrnet_time_per_image) * 100
            
            overhead_analysis[name] = {
                'time_per_tile_s': time_per_tile_s,
                'total_overhead_s': total_overhead_per_image,
                'overhead_percentage': overhead_percentage,
                'acceptable': overhead_percentage < 5.0  # 5%ä»¥ä¸‹å¯æ¥å—
            }
            
            print(f"\n{name}:")
            print(f"  æ¯tileæ—¶é—´: {time_per_tile_s*1000:.4f}ms")
            print(f"  æ¯å›¾åƒæ€»å¼€é”€: {total_overhead_per_image:.3f}s")
            print(f"  ç›¸å¯¹IBRNetå¼€é”€: {overhead_percentage:.2f}%")
            print(f"  å¯æ¥å—æ€§: {'âœ…' if overhead_analysis[name]['acceptable'] else 'âŒ'}")
        
        return overhead_analysis
    
    def create_visualization(self, speed_results, accuracy_results, overhead_analysis):
        """åˆ›å»ºå¯è§†åŒ–å›¾è¡¨"""
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))
        
        # 1. é€Ÿåº¦å¯¹æ¯”
        methods = list(speed_results.keys())
        times = [speed_results[m]['avg_time_per_tile_ms'] for m in methods]
        
        bars = ax1.bar(methods, times, color=['gray', 'blue', 'red', 'green'][:len(methods)])
        ax1.set_ylabel('Time per Tile (ms)')
        ax1.set_title('Speed Comparison: Time per Tile')
        ax1.set_yscale('log')
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, time in zip(bars, times):
            ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height(), 
                    f'{time:.4f}', ha='center', va='bottom')
        
        # 2. ååé‡å¯¹æ¯”
        throughputs = [speed_results[m]['throughput_tiles_per_sec'] for m in methods]
        ax2.bar(methods, throughputs, color=['gray', 'blue', 'red', 'green'][:len(methods)])
        ax2.set_ylabel('Throughput (tiles/sec)')
        ax2.set_title('Throughput Comparison')
        
        # 3. è®¡ç®—å¼€é”€ç™¾åˆ†æ¯”
        overhead_methods = list(overhead_analysis.keys())
        overheads = [overhead_analysis[m]['overhead_percentage'] for m in overhead_methods]
        colors = ['green' if overhead_analysis[m]['acceptable'] else 'red' 
                 for m in overhead_methods]
        
        bars = ax3.bar(overhead_methods, overheads, color=colors, alpha=0.7)
        ax3.set_ylabel('Overhead Percentage (%)')
        ax3.set_title('Computational Overhead vs IBRNet')
        ax3.axhline(y=5, color='red', linestyle='--', label='5% Threshold')
        ax3.legend()
        
        # 4. ä¸Cannyä¸€è‡´æ€§
        if accuracy_results:
            neural_methods = list(accuracy_results.keys())
            agreements = [accuracy_results[m]['agreement_with_canny'] for m in neural_methods]
            ax4.bar(neural_methods, agreements, color=['blue', 'red', 'green'][:len(neural_methods)])
            ax4.set_ylabel('Agreement with Canny')
            ax4.set_title('Prediction Agreement with Canny Baseline')
            ax4.set_ylim(0, 1)
        
        plt.tight_layout()
        
        # ä¿å­˜å›¾è¡¨
        output_path = "/home/ytanaz/access/IBRNet/test_sr/results/neural_predictor_benchmark.png"
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        print(f"\nğŸ“Š å›¾è¡¨ä¿å­˜åˆ°: {output_path}")
        
        return output_path

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ§  è½»é‡çº§ç¥ç»ç½‘ç»œtileå¤æ‚åº¦é¢„æµ‹å™¨åŸºå‡†æµ‹è¯•")
    print("="*60)
    
    benchmark = NeuralPredictorBenchmark()
    
    # 1. é€Ÿåº¦æµ‹è¯•
    speed_results = benchmark.benchmark_speed(num_iterations=100)
    
    # 2. å‡†ç¡®æ€§æµ‹è¯•  
    accuracy_results = benchmark.benchmark_accuracy()
    
    # 3. è®¡ç®—å¼€é”€åˆ†æ
    overhead_analysis = benchmark.analyze_computational_overhead()
    
    # 4. åˆ›å»ºå¯è§†åŒ–
    chart_path = benchmark.create_visualization(speed_results, accuracy_results, overhead_analysis)
    
    # 5. ç”ŸæˆæŠ¥å‘Š
    print("\n" + "="*60)
    print("ğŸ“‹ åŸºå‡†æµ‹è¯•æ€»ç»“")
    print("="*60)
    
    print("\nğŸ† æ¨èæ–¹æ¡ˆ:")
    acceptable_methods = [name for name, analysis in overhead_analysis.items() 
                         if analysis['acceptable']]
    
    if acceptable_methods:
        fastest_acceptable = min(acceptable_methods, 
                               key=lambda x: speed_results[x]['avg_time_per_tile_ms'])
        print(f"  æœ€ä½³é€‰æ‹©: {fastest_acceptable}")
        print(f"  å¼€é”€: {overhead_analysis[fastest_acceptable]['overhead_percentage']:.2f}%")
        print(f"  é€Ÿåº¦: {speed_results[fastest_acceptable]['avg_time_per_tile_ms']:.4f}ms/tile")
        
        if fastest_acceptable in accuracy_results:
            print(f"  ä¸Cannyä¸€è‡´æ€§: {accuracy_results[fastest_acceptable]['agreement_with_canny']:.3f}")
    else:
        print("  âš ï¸  æ‰€æœ‰ç¥ç»ç½‘ç»œæ–¹æ³•çš„å¼€é”€éƒ½è¶…è¿‡5%é˜ˆå€¼")
        print("  å»ºè®®ç»§ç»­ä½¿ç”¨Cannyæ–¹æ³•")
    
    print(f"\nğŸ“Š è¯¦ç»†ç»“æœå›¾è¡¨: {chart_path}")

if __name__ == "__main__":
    main()
